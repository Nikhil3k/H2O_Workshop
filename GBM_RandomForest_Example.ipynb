{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "This tutorial shows how H2O [Gradient Boosted Models](https://en.wikipedia.org/wiki/Gradient_boosting) and [Random Forest](https://en.wikipedia.org/wiki/Random_forest) models can be used to do supervised classification and regression. This tutorial covers usage of H2O from Python. An R version of this tutorial will be available as well in a separate document. This file is available in plain R, R markdown, regular markdown, plain Python and iPython Notebook formats. More examples and explanations can be found in our [H2O GBM booklet](http://h2o.ai/resources/) and on our [H2O Github Repository](http://github.com/h2oai/h2o-3/).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task: Predicting forest cover type from cartographic variables only\n",
    "\n",
    "The actual forest cover type for a given observation (30 x 30 meter cell) was determined from the US Forest Service (USFS). We are using the UC Irvine Covertype dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### H2O Python Module\n",
    "\n",
    "Load the H2O Python module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import h2o\n",
    "from h2o.automl import H2OAutoML\n",
    "import random, os, sys\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import logging\n",
    "import csv\n",
    "import optparse\n",
    "import time\n",
    "import json\n",
    "from distutils.util import strtobool\n",
    "import psutil\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "pct_memory=0.5\n",
    "virtual_memory=psutil.virtual_memory()\n",
    "min_mem_size=int(round(int(pct_memory*virtual_memory.available)/1073741824,0))\n",
    "print(min_mem_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking whether there is an H2O instance running at http://localhost:32448..... not found.\n",
      "Attempting to start a local H2O server...\n",
      "  Java Version: openjdk version \"1.8.0_121\"; OpenJDK Runtime Environment (Zulu 8.20.0.5-macosx) (build 1.8.0_121-b15); OpenJDK 64-Bit Server VM (Zulu 8.20.0.5-macosx) (build 25.121-b15, mixed mode)\n",
      "  Starting server from /Users/bear/anaconda/lib/python3.6/site-packages/h2o/backend/bin/h2o.jar\n",
      "  Ice root: /var/folders/lh/42j8mfjx069d1bkc2wlf2pw40000gn/T/tmpw8b_7nb8\n",
      "  JVM stdout: /var/folders/lh/42j8mfjx069d1bkc2wlf2pw40000gn/T/tmpw8b_7nb8/h2o_bear_started_from_python.out\n",
      "  JVM stderr: /var/folders/lh/42j8mfjx069d1bkc2wlf2pw40000gn/T/tmpw8b_7nb8/h2o_bear_started_from_python.err\n",
      "  Server is running at http://127.0.0.1:32448\n",
      "Connecting to H2O server at http://127.0.0.1:32448... successful.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td>H2O cluster uptime:</td>\n",
       "<td>01 secs</td></tr>\n",
       "<tr><td>H2O cluster timezone:</td>\n",
       "<td>America/New_York</td></tr>\n",
       "<tr><td>H2O data parsing timezone:</td>\n",
       "<td>UTC</td></tr>\n",
       "<tr><td>H2O cluster version:</td>\n",
       "<td>3.22.1.3</td></tr>\n",
       "<tr><td>H2O cluster version age:</td>\n",
       "<td>14 days, 19 hours and 19 minutes </td></tr>\n",
       "<tr><td>H2O cluster name:</td>\n",
       "<td>H2O_from_python_bear_bqt8w0</td></tr>\n",
       "<tr><td>H2O cluster total nodes:</td>\n",
       "<td>1</td></tr>\n",
       "<tr><td>H2O cluster free memory:</td>\n",
       "<td>3.556 Gb</td></tr>\n",
       "<tr><td>H2O cluster total cores:</td>\n",
       "<td>8</td></tr>\n",
       "<tr><td>H2O cluster allowed cores:</td>\n",
       "<td>8</td></tr>\n",
       "<tr><td>H2O cluster status:</td>\n",
       "<td>accepting new members, healthy</td></tr>\n",
       "<tr><td>H2O connection url:</td>\n",
       "<td>http://127.0.0.1:32448</td></tr>\n",
       "<tr><td>H2O connection proxy:</td>\n",
       "<td>None</td></tr>\n",
       "<tr><td>H2O internal security:</td>\n",
       "<td>False</td></tr>\n",
       "<tr><td>H2O API Extensions:</td>\n",
       "<td>XGBoost, Algos, AutoML, Core V3, Core V4</td></tr>\n",
       "<tr><td>Python version:</td>\n",
       "<td>3.6.5 final</td></tr></table></div>"
      ],
      "text/plain": [
       "--------------------------  ----------------------------------------\n",
       "H2O cluster uptime:         01 secs\n",
       "H2O cluster timezone:       America/New_York\n",
       "H2O data parsing timezone:  UTC\n",
       "H2O cluster version:        3.22.1.3\n",
       "H2O cluster version age:    14 days, 19 hours and 19 minutes\n",
       "H2O cluster name:           H2O_from_python_bear_bqt8w0\n",
       "H2O cluster total nodes:    1\n",
       "H2O cluster free memory:    3.556 Gb\n",
       "H2O cluster total cores:    8\n",
       "H2O cluster allowed cores:  8\n",
       "H2O cluster status:         accepting new members, healthy\n",
       "H2O connection url:         http://127.0.0.1:32448\n",
       "H2O connection proxy:\n",
       "H2O internal security:      False\n",
       "H2O API Extensions:         XGBoost, Algos, AutoML, Core V3, Core V4\n",
       "Python version:             3.6.5 final\n",
       "--------------------------  ----------------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 65535 Highest port no\n",
    "port_no=random.randint(5555,55555)\n",
    "h2o.init(strict_version_check=False,min_mem_size_GB=min_mem_size,port=port_no) # start h2o"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To learn more about the h2o package itself, we can use Python's builtin help() function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on package h2o:\n",
      "\n",
      "NAME\n",
      "    h2o - :mod:`h2o` -- module for using H2O services.\n",
      "\n",
      "DESCRIPTION\n",
      "    (please add description).\n",
      "\n",
      "PACKAGE CONTENTS\n",
      "    assembly\n",
      "    astfun\n",
      "    auth\n",
      "    automl (package)\n",
      "    backend (package)\n",
      "    cross_validation\n",
      "    demos\n",
      "    display\n",
      "    estimators (package)\n",
      "    exceptions\n",
      "    expr\n",
      "    expr_optimizer\n",
      "    frame\n",
      "    grid (package)\n",
      "    group_by\n",
      "    h2o\n",
      "    job\n",
      "    model (package)\n",
      "    schemas (package)\n",
      "    targetencoder\n",
      "    transforms (package)\n",
      "    tree (package)\n",
      "    two_dim_table\n",
      "    utils (package)\n",
      "\n",
      "FUNCTIONS\n",
      "    api(endpoint, data=None, json=None, filename=None, save_to=None)\n",
      "        Perform a REST API request to a previously connected server.\n",
      "        \n",
      "        This function is mostly for internal purposes, but may occasionally be useful for direct access to\n",
      "        the backend H2O server. It has same parameters as :meth:`H2OConnection.request <h2o.backend.H2OConnection.request>`.\n",
      "    \n",
      "    as_list(data, use_pandas=True, header=True)\n",
      "        Convert an H2O data object into a python-specific object.\n",
      "        \n",
      "        WARNING! This will pull all data local!\n",
      "        \n",
      "        If Pandas is available (and use_pandas is True), then pandas will be used to parse the\n",
      "        data frame. Otherwise, a list-of-lists populated by character data will be returned (so\n",
      "        the types of data will all be str).\n",
      "        \n",
      "        :param data: an H2O data object.\n",
      "        :param use_pandas: If True, try to use pandas for reading in the data.\n",
      "        :param header: If True, return column names as first element in list\n",
      "        \n",
      "        :returns: List of lists (Rows x Columns).\n",
      "    \n",
      "    assign(data, xid)\n",
      "        (internal) Assign new id to the frame.\n",
      "        \n",
      "        :param data: an H2OFrame whose id should be changed\n",
      "        :param xid: new id for the frame.\n",
      "        :returns: the passed frame.\n",
      "    \n",
      "    cluster()\n",
      "        Return :class:`H2OCluster` object describing the backend H2O cloud.\n",
      "    \n",
      "    cluster_info(*args, **kwargs)\n",
      "        Deprecated, use ``h2o.cluster().show_status()``.\n",
      "    \n",
      "    cluster_status(*args, **kwargs)\n",
      "        Deprecated, use ``h2o.cluster().show_status(True)``.\n",
      "    \n",
      "    connect(server=None, url=None, ip=None, port=None, https=None, verify_ssl_certificates=None, auth=None, proxy=None, cookies=None, verbose=True, config=None)\n",
      "        Connect to an existing H2O server, remote or local.\n",
      "        \n",
      "        There are two ways to connect to a server: either pass a `server` parameter containing an instance of\n",
      "        an H2OLocalServer, or specify `ip` and `port` of the server that you want to connect to.\n",
      "        \n",
      "        :param server: An H2OLocalServer instance to connect to (optional).\n",
      "        :param url: Full URL of the server to connect to (can be used instead of `ip` + `port` + `https`).\n",
      "        :param ip: The ip address (or host name) of the server where H2O is running.\n",
      "        :param port: Port number that H2O service is listening to.\n",
      "        :param https: Set to True to connect via https:// instead of http://.\n",
      "        :param verify_ssl_certificates: When using https, setting this to False will disable SSL certificates verification.\n",
      "        :param auth: Either a (username, password) pair for basic authentication, an instance of h2o.auth.SpnegoAuth\n",
      "                     or one of the requests.auth authenticator objects.\n",
      "        :param proxy: Proxy server address.\n",
      "        :param cookies: Cookie (or list of) to add to request\n",
      "        :param verbose: Set to False to disable printing connection status messages.\n",
      "        :param connection_conf: Connection configuration object encapsulating connection parameters.\n",
      "        :returns: the new :class:`H2OConnection` object.\n",
      "    \n",
      "    connection()\n",
      "        Return the current :class:`H2OConnection` handler.\n",
      "    \n",
      "    create_frame(frame_id=None, rows=10000, cols=10, randomize=True, real_fraction=None, categorical_fraction=None, integer_fraction=None, binary_fraction=None, time_fraction=None, string_fraction=None, value=0, real_range=100, factors=100, integer_range=100, binary_ones_fraction=0.02, missing_fraction=0.01, has_response=False, response_factors=2, positive_response=False, seed=None, seed_for_column_types=None)\n",
      "        Create a new frame with random data.\n",
      "        \n",
      "        Creates a data frame in H2O with real-valued, categorical, integer, and binary columns specified by the user.\n",
      "        \n",
      "        :param frame_id: the destination key. If empty, this will be auto-generated.\n",
      "        :param rows: the number of rows of data to generate.\n",
      "        :param cols: the number of columns of data to generate. Excludes the response column if has_response is True.\n",
      "        :param randomize: If True, data values will be randomly generated. This must be True if either\n",
      "            categorical_fraction or integer_fraction is non-zero.\n",
      "        :param value: if randomize is False, then all real-valued entries will be set to this value.\n",
      "        :param real_range: the range of randomly generated real values.\n",
      "        :param real_fraction: the fraction of columns that are real-valued.\n",
      "        :param categorical_fraction: the fraction of total columns that are categorical.\n",
      "        :param factors: the number of (unique) factor levels in each categorical column.\n",
      "        :param integer_fraction: the fraction of total columns that are integer-valued.\n",
      "        :param integer_range: the range of randomly generated integer values.\n",
      "        :param binary_fraction: the fraction of total columns that are binary-valued.\n",
      "        :param binary_ones_fraction: the fraction of values in a binary column that are set to 1.\n",
      "        :param time_fraction: the fraction of randomly created date/time columns.\n",
      "        :param string_fraction: the fraction of randomly created string columns.\n",
      "        :param missing_fraction: the fraction of total entries in the data frame that are set to NA.\n",
      "        :param has_response: A logical value indicating whether an additional response column should be prepended to the\n",
      "            final H2O data frame. If set to True, the total number of columns will be ``cols + 1``.\n",
      "        :param response_factors: if has_response is True, then this variable controls the type of the \"response\" column:\n",
      "            setting response_factors to 1 will generate real-valued response, any value greater or equal than 2 will\n",
      "            create categorical response with that many categories.\n",
      "        :param positive_reponse: when response variable is present and of real type, this will control whether it\n",
      "            contains positive values only, or both positive and negative.\n",
      "        :param seed: a seed used to generate random values when ``randomize`` is True.\n",
      "        :param seed_for_column_types: a seed used to generate random column types when ``randomize`` is True.\n",
      "        \n",
      "        :returns: an :class:`H2OFrame` object\n",
      "    \n",
      "    deep_copy(data, xid)\n",
      "        Create a deep clone of the frame ``data``.\n",
      "        \n",
      "        :param data: an H2OFrame to be cloned\n",
      "        :param xid: (internal) id to be assigned to the new frame.\n",
      "        :returns: new :class:`H2OFrame` which is the clone of the passed frame.\n",
      "    \n",
      "    demo(funcname, interactive=True, echo=True, test=False)\n",
      "        H2O built-in demo facility.\n",
      "        \n",
      "        :param funcname: A string that identifies the h2o python function to demonstrate.\n",
      "        :param interactive: If True, the user will be prompted to continue the demonstration after every segment.\n",
      "        :param echo: If True, the python commands that are executed will be displayed.\n",
      "        :param test: If True, `h2o.init()` will not be called (used for pyunit testing).\n",
      "        \n",
      "        :example:\n",
      "            >>> import h2o\n",
      "            >>> h2o.demo(\"gbm\")\n",
      "    \n",
      "    download_all_logs(dirname='.', filename=None)\n",
      "        Download H2O log files to disk.\n",
      "        \n",
      "        :param dirname: a character string indicating the directory that the log file should be saved in.\n",
      "        :param filename: a string indicating the name that the CSV file should be. Note that the saved format is .zip, so the file name must include the .zip extension.\n",
      "        \n",
      "        :returns: path of logs written in a zip file.\n",
      "        \n",
      "        :examples: The following code will save the zip file `'autoh2o_log.zip'` in a directory that is one down from where you are currently working into a directory called `your_directory_name`. (Please note that `your_directory_name` should be replaced with the name of the directory that you've created and that already exists.)\n",
      "        \n",
      "            >>> h2o.download_all_logs(dirname='./your_directory_name/', filename = 'autoh2o_log.zip')\n",
      "    \n",
      "    download_csv(data, filename)\n",
      "        Download an H2O data set to a CSV file on the local disk.\n",
      "        \n",
      "        Warning: Files located on the H2O server may be very large! Make sure you have enough\n",
      "        hard drive space to accommodate the entire file.\n",
      "        \n",
      "        :param data: an H2OFrame object to be downloaded.\n",
      "        :param filename: name for the CSV file where the data should be saved to.\n",
      "    \n",
      "    download_pojo(model, path='', get_jar=True, jar_name='')\n",
      "        Download the POJO for this model to the directory specified by path; if path is \"\", then dump to screen.\n",
      "        \n",
      "        :param model: the model whose scoring POJO should be retrieved.\n",
      "        :param path: an absolute path to the directory where POJO should be saved.\n",
      "        :param get_jar: retrieve the h2o-genmodel.jar also (will be saved to the same folder ``path``).\n",
      "        :param jar_name: Custom name of genmodel jar.\n",
      "        :returns: location of the downloaded POJO file.\n",
      "    \n",
      "    enable_expr_optimizations(flag)\n",
      "        Enable expression tree local optimizations.\n",
      "    \n",
      "    export_file(frame, path, force=False, parts=1)\n",
      "        Export a given H2OFrame to a path on the machine this python session is currently connected to.\n",
      "        \n",
      "        :param frame: the Frame to save to disk.\n",
      "        :param path: the path to the save point on disk.\n",
      "        :param force: if True, overwrite any preexisting file with the same path\n",
      "        :param parts: enables export to multiple 'part' files instead of just a single file.\n",
      "            Convenient for large datasets that take too long to store in a single file.\n",
      "            Use parts=-1 to instruct H2O to determine the optimal number of part files or\n",
      "            specify your desired maximum number of part files. Path needs to be a directory\n",
      "            when exporting to multiple files, also that directory must be empty.\n",
      "            Default is ``parts = 1``, which is to export to a single file.\n",
      "    \n",
      "    flow()\n",
      "        Open H2O Flow in your browser.\n",
      "    \n",
      "    frame(frame_id)\n",
      "        Retrieve metadata for an id that points to a Frame.\n",
      "        \n",
      "        :param frame_id: the key of a Frame in H2O.\n",
      "        \n",
      "        :returns: dict containing the frame meta-information.\n",
      "    \n",
      "    frames()\n",
      "        Retrieve all the Frames.\n",
      "        \n",
      "        :returns: Meta information on the frames\n",
      "    \n",
      "    get_frame(frame_id, **kwargs)\n",
      "        Obtain a handle to the frame in H2O with the frame_id key.\n",
      "        \n",
      "        :param str frame_id: id of the frame to retrieve.\n",
      "        :returns: an :class:`H2OFrame` object\n",
      "    \n",
      "    get_grid(grid_id)\n",
      "        Return the specified grid.\n",
      "        \n",
      "        :param grid_id: The grid identification in h2o\n",
      "        \n",
      "        :returns: an :class:`H2OGridSearch` instance.\n",
      "    \n",
      "    get_model(model_id)\n",
      "        Load a model from the server.\n",
      "        \n",
      "        :param model_id: The model identification in H2O\n",
      "        \n",
      "        :returns: Model object, a subclass of H2OEstimator\n",
      "    \n",
      "    get_timezone(*args, **kwargs)\n",
      "        Deprecated, use ``h2o.cluster().timezone``.\n",
      "    \n",
      "    import_file(path=None, destination_frame=None, parse=True, header=0, sep=None, col_names=None, col_types=None, na_strings=None, pattern=None, skipped_columns=None)\n",
      "        Import a dataset that is already on the cluster.\n",
      "        \n",
      "        The path to the data must be a valid path for each node in the H2O cluster. If some node in the H2O cluster\n",
      "        cannot see the file, then an exception will be thrown by the H2O cluster. Does a parallel/distributed\n",
      "        multi-threaded pull of the data. The main difference between this method and :func:`upload_file` is that\n",
      "        the latter works with local files, whereas this method imports remote files (i.e. files local to the server).\n",
      "        If you running H2O server on your own maching, then both methods behave the same.\n",
      "        \n",
      "        :param path: path(s) specifying the location of the data to import or a path to a directory of files to import\n",
      "        :param destination_frame: The unique hex key assigned to the imported file. If none is given, a key will be\n",
      "            automatically generated.\n",
      "        :param parse: If True, the file should be parsed after import. If False, then a list is returned containing the file path.\n",
      "        :param header: -1 means the first line is data, 0 means guess, 1 means first line is header.\n",
      "        :param sep: The field separator character. Values on each line of the file are separated by\n",
      "            this character. If not provided, the parser will automatically detect the separator.\n",
      "        :param col_names: A list of column names for the file.\n",
      "        :param col_types: A list of types or a dictionary of column names to types to specify whether columns\n",
      "            should be forced to a certain type upon import parsing. If a list, the types for elements that are\n",
      "            one will be guessed. The possible types a column may have are:\n",
      "        \n",
      "            - \"unknown\" - this will force the column to be parsed as all NA\n",
      "            - \"uuid\"    - the values in the column must be true UUID or will be parsed as NA\n",
      "            - \"string\"  - force the column to be parsed as a string\n",
      "            - \"numeric\" - force the column to be parsed as numeric. H2O will handle the compression of the numeric\n",
      "              data in the optimal manner.\n",
      "            - \"enum\"    - force the column to be parsed as a categorical column.\n",
      "            - \"time\"    - force the column to be parsed as a time column. H2O will attempt to parse the following\n",
      "              list of date time formats: (date) \"yyyy-MM-dd\", \"yyyy MM dd\", \"dd-MMM-yy\", \"dd MMM yy\", (time)\n",
      "              \"HH:mm:ss\", \"HH:mm:ss:SSS\", \"HH:mm:ss:SSSnnnnnn\", \"HH.mm.ss\" \"HH.mm.ss.SSS\", \"HH.mm.ss.SSSnnnnnn\".\n",
      "              Times can also contain \"AM\" or \"PM\".\n",
      "        :param na_strings: A list of strings, or a list of lists of strings (one list per column), or a dictionary\n",
      "            of column names to strings which are to be interpreted as missing values.\n",
      "        :param pattern: Character string containing a regular expression to match file(s) in the folder if `path` is a\n",
      "            directory.\n",
      "        :param skipped_columns: an integer list of column indices to skip and not parsed into the final frame from the import file.\n",
      "        \n",
      "        :returns: a new :class:`H2OFrame` instance.\n",
      "        \n",
      "        :examples:\n",
      "            >>> # Single file import\n",
      "            >>> iris = import_file(\"h2o-3/smalldata/iris.csv\")\n",
      "            >>> # Return all files in the folder iris/ matching the regex r\"iris_.*\\.csv\"\n",
      "            >>> iris_pattern = h2o.import_file(path = \"h2o-3/smalldata/iris\",\n",
      "            ...                                pattern = \"iris_.*\\.csv\")\n",
      "    \n",
      "    import_sql_select(connection_url, select_query, username, password, optimize=True, fetch_mode=None)\n",
      "        Import the SQL table that is the result of the specified SQL query to H2OFrame in memory.\n",
      "        \n",
      "        Creates a temporary SQL table from the specified sql_query.\n",
      "        Runs multiple SELECT SQL queries on the temporary table concurrently for parallel ingestion, then drops the table.\n",
      "        Be sure to start the h2o.jar in the terminal with your downloaded JDBC driver in the classpath::\n",
      "        \n",
      "          java -cp <path_to_h2o_jar>:<path_to_jdbc_driver_jar> water.H2OApp\n",
      "        \n",
      "        Also see h2o.import_sql_table. Currently supported SQL databases are MySQL, PostgreSQL, and MariaDB. Support\n",
      "        for Oracle 12g and Microsoft SQL Server is forthcoming.\n",
      "        \n",
      "        :param connection_url: URL of the SQL database connection as specified by the Java Database Connectivity (JDBC)\n",
      "            Driver. For example, \"jdbc:mysql://localhost:3306/menagerie?&useSSL=false\"\n",
      "        :param select_query: SQL query starting with `SELECT` that returns rows from one or more database tables.\n",
      "        :param username: username for SQL server\n",
      "        :param password: password for SQL server\n",
      "        :param optimize: DEPRECATED. Ignored - use fetch_mode instead. Optimize import of SQL table for faster imports.\n",
      "        :param fetch_mode: Set to DISTRIBUTED to enable distributed import. Set to SINGLE to force a sequential read by a single node\n",
      "            from the database.\n",
      "        \n",
      "        :returns: an :class:`H2OFrame` containing data of the specified SQL query.\n",
      "        \n",
      "        :examples:\n",
      "            >>> conn_url = \"jdbc:mysql://172.16.2.178:3306/ingestSQL?&useSSL=false\"\n",
      "            >>> select_query = \"SELECT bikeid from citibike20k\"\n",
      "            >>> username = \"root\"\n",
      "            >>> password = \"abc123\"\n",
      "            >>> my_citibike_data = h2o.import_sql_select(conn_url, select_query,\n",
      "            ...                                          username, password, fetch_mode)\n",
      "    \n",
      "    import_sql_table(connection_url, table, username, password, columns=None, optimize=True, fetch_mode=None)\n",
      "        Import SQL table to H2OFrame in memory.\n",
      "        \n",
      "        Assumes that the SQL table is not being updated and is stable.\n",
      "        Runs multiple SELECT SQL queries concurrently for parallel ingestion.\n",
      "        Be sure to start the h2o.jar in the terminal with your downloaded JDBC driver in the classpath::\n",
      "        \n",
      "            java -cp <path_to_h2o_jar>:<path_to_jdbc_driver_jar> water.H2OApp\n",
      "        \n",
      "        Also see :func:`import_sql_select`.\n",
      "        Currently supported SQL databases are MySQL, PostgreSQL, MariaDB, and Netezza. Support for Oracle 12g and Microsoft SQL\n",
      "        Server is forthcoming.\n",
      "        \n",
      "        :param connection_url: URL of the SQL database connection as specified by the Java Database Connectivity (JDBC)\n",
      "            Driver. For example, \"jdbc:mysql://localhost:3306/menagerie?&useSSL=false\"\n",
      "        :param table: name of SQL table\n",
      "        :param columns: a list of column names to import from SQL table. Default is to import all columns.\n",
      "        :param username: username for SQL server\n",
      "        :param password: password for SQL server\n",
      "        :param optimize: DEPRECATED. Ignored - use fetch_mode instead. Optimize import of SQL table for faster imports.\n",
      "        :param fetch_mode: Set to DISTRIBUTED to enable distributed import. Set to SINGLE to force a sequential read by a single node\n",
      "            from the database.\n",
      "        \n",
      "        :returns: an :class:`H2OFrame` containing data of the specified SQL table.\n",
      "        \n",
      "        :examples:\n",
      "            >>> conn_url = \"jdbc:mysql://172.16.2.178:3306/ingestSQL?&useSSL=false\"\n",
      "            >>> table = \"citibike20k\"\n",
      "            >>> username = \"root\"\n",
      "            >>> password = \"abc123\"\n",
      "            >>> my_citibike_data = h2o.import_sql_table(conn_url, table, username, password)\n",
      "    \n",
      "    init(url=None, ip=None, port=None, name=None, https=None, insecure=None, username=None, password=None, cookies=None, proxy=None, start_h2o=True, nthreads=-1, ice_root=None, log_dir=None, log_level=None, enable_assertions=True, max_mem_size=None, min_mem_size=None, strict_version_check=None, ignore_config=False, extra_classpath=None, jvm_custom_args=None, bind_to_localhost=True, **kwargs)\n",
      "        Attempt to connect to a local server, or if not successful start a new server and connect to it.\n",
      "        \n",
      "        :param url: Full URL of the server to connect to (can be used instead of `ip` + `port` + `https`).\n",
      "        :param ip: The ip address (or host name) of the server where H2O is running.\n",
      "        :param port: Port number that H2O service is listening to.\n",
      "        :param name: cloud name. If None while connecting to an existing cluster it will not check the cloud name.\n",
      "                     If set then will connect only if the target cloud name matches. If no instance is found and decides to start a local\n",
      "                     one then this will be used as the cloud name or a random one will be generated if set to None.\n",
      "        :param https: Set to True to connect via https:// instead of http://.\n",
      "        :param insecure: When using https, setting this to True will disable SSL certificates verification.\n",
      "        :param username: Username and\n",
      "        :param password: Password for basic authentication.\n",
      "        :param cookies: Cookie (or list of) to add to each request.\n",
      "        :param proxy: Proxy server address.\n",
      "        :param start_h2o: If False, do not attempt to start an h2o server when connection to an existing one failed.\n",
      "        :param nthreads: \"Number of threads\" option when launching a new h2o server.\n",
      "        :param ice_root: Directory for temporary files for the new h2o server.\n",
      "        :param log_dir: Directory for H2O logs to be stored if a new instance is started. Ignored if connecting to an existing node.\n",
      "        :param log_level: The logger level for H2O if a new instance is started. One of TRACE,DEBUG,INFO,WARN,ERRR,FATA. Default is INFO. Ignored if connecting to an existing node.\n",
      "        :param enable_assertions: Enable assertions in Java for the new h2o server.\n",
      "        :param max_mem_size: Maximum memory to use for the new h2o server. Integer input will be evaluated as gigabytes.  Other units can be specified by passing in a string (e.g. \"160M\" for 160 megabytes).\n",
      "        :param min_mem_size: Minimum memory to use for the new h2o server. Integer input will be evaluated as gigabytes.  Other units can be specified by passing in a string (e.g. \"160M\" for 160 megabytes).\n",
      "        :param strict_version_check: If True, an error will be raised if the client and server versions don't match.\n",
      "        :param ignore_config: Indicates whether a processing of a .h2oconfig file should be conducted or not. Default value is False.\n",
      "        :param extra_classpath: List of paths to libraries that should be included on the Java classpath when starting H2O from Python.\n",
      "        :param kwargs: (all other deprecated attributes)\n",
      "        :param jvm_custom_args: Customer, user-defined argument's for the JVM H2O is instantiated in. Ignored if there is an instance of H2O already running and the client connects to it.\n",
      "    \n",
      "    interaction(data, factors, pairwise, max_factors, min_occurrence, destination_frame=None)\n",
      "        Categorical Interaction Feature Creation in H2O.\n",
      "        \n",
      "        Creates a frame in H2O with n-th order interaction features between categorical columns, as specified by\n",
      "        the user.\n",
      "        \n",
      "        :param data: the H2OFrame that holds the target categorical columns.\n",
      "        :param factors: factor columns (either indices or column names).\n",
      "        :param pairwise: If True, create pairwise interactions between factors (otherwise create one\n",
      "            higher-order interaction). Only applicable if there are 3 or more factors.\n",
      "        :param max_factors: Max. number of factor levels in pair-wise interaction terms (if enforced, one extra\n",
      "            catch-all factor will be made).\n",
      "        :param min_occurrence: Min. occurrence threshold for factor levels in pair-wise interaction terms\n",
      "        :param destination_frame: a string indicating the destination key. If empty, this will be auto-generated by H2O.\n",
      "        \n",
      "        :returns: :class:`H2OFrame`\n",
      "    \n",
      "    is_expr_optimizations_enabled()\n",
      "    \n",
      "    lazy_import(path, pattern=None)\n",
      "        Import a single file or collection of files.\n",
      "        \n",
      "        :param path: A path to a data file (remote or local).\n",
      "        :param pattern: Character string containing a regular expression to match file(s) in the folder.\n",
      "        :returns: either a :class:`H2OFrame` with the content of the provided file, or a list of such frames if\n",
      "            importing multiple files.\n",
      "    \n",
      "    list_timezones(*args, **kwargs)\n",
      "        Deprecated, use ``h2o.cluster().list_timezones()``.\n",
      "    \n",
      "    load_dataset(relative_path)\n",
      "        Imports a data file within the 'h2o_data' folder.\n",
      "    \n",
      "    load_model(path)\n",
      "        Load a saved H2O model from disk. (Note that ensemble binary models can now be loaded using this method.)\n",
      "        \n",
      "        :param path: the full path of the H2O Model to be imported.\n",
      "        \n",
      "        :returns: an :class:`H2OEstimator` object\n",
      "        \n",
      "        :examples:\n",
      "            >>> path = h2o.save_model(my_model, dir=my_path)\n",
      "            >>> h2o.load_model(path)\n",
      "    \n",
      "    log_and_echo(message='')\n",
      "        Log a message on the server-side logs.\n",
      "        \n",
      "        This is helpful when running several pieces of work one after the other on a single H2O\n",
      "        cluster and you want to make a notation in the H2O server side log where one piece of\n",
      "        work ends and the next piece of work begins.\n",
      "        \n",
      "        Sends a message to H2O for logging. Generally used for debugging purposes.\n",
      "        \n",
      "        :param message: message to write to the log.\n",
      "    \n",
      "    ls()\n",
      "        List keys on an H2O Cluster.\n",
      "    \n",
      "    make_metrics(predicted, actual, domain=None, distribution=None)\n",
      "        Create Model Metrics from predicted and actual values in H2O.\n",
      "        \n",
      "        :param H2OFrame predicted: an H2OFrame containing predictions.\n",
      "        :param H2OFrame actuals: an H2OFrame containing actual values.\n",
      "        :param domain: list of response factors for classification.\n",
      "        :param distribution: distribution for regression.\n",
      "    \n",
      "    mojo_predict_csv(input_csv_path, mojo_zip_path, output_csv_path=None, genmodel_jar_path=None, classpath=None, java_options=None, verbose=False)\n",
      "        MOJO scoring function to take a CSV file and use MOJO model as zip file to score.\n",
      "        \n",
      "        :param input_csv_path: Path to input CSV file.\n",
      "        :param mojo_zip_path: Path to MOJO zip downloaded from H2O.\n",
      "        :param output_csv_path: Optional, name of the output CSV file with computed predictions. If None (default), then\n",
      "            predictions will be saved as prediction.csv in the same folder as the MOJO zip.\n",
      "        :param genmodel_jar_path: Optional, path to genmodel jar file. If None (default) then the h2o-genmodel.jar in the same\n",
      "            folder as the MOJO zip will be used.\n",
      "        :param classpath: Optional, specifies custom user defined classpath which will be used when scoring. If None\n",
      "            (default) then the default classpath for this MOJO model will be used.\n",
      "        :param java_options: Optional, custom user defined options for Java. By default ``-Xmx4g -XX:ReservedCodeCacheSize=256m`` is used.\n",
      "        :param verbose: Optional, if True, then additional debug information will be printed. False by default.\n",
      "        :return: List of computed predictions\n",
      "    \n",
      "    mojo_predict_pandas(dataframe, mojo_zip_path, genmodel_jar_path=None, classpath=None, java_options=None, verbose=False)\n",
      "        MOJO scoring function to take a Pandas frame and use MOJO model as zip file to score.\n",
      "        \n",
      "        :param dataframe: Pandas frame to score.\n",
      "        :param mojo_zip_path: Path to MOJO zip downloaded from H2O.\n",
      "        :param genmodel_jar_path: Optional, path to genmodel jar file. If None (default) then the h2o-genmodel.jar in the same\n",
      "            folder as the MOJO zip will be used.\n",
      "        :param classpath: Optional, specifies custom user defined classpath which will be used when scoring. If None\n",
      "            (default) then the default classpath for this MOJO model will be used.\n",
      "        :param java_options: Optional, custom user defined options for Java. By default ``-Xmx4g`` is used.\n",
      "        :param verbose: Optional, if True, then additional debug information will be printed. False by default.\n",
      "        :return: Pandas frame with predictions\n",
      "    \n",
      "    network_test(*args, **kwargs)\n",
      "        Deprecated, use ``h2o.cluster().network_test()``.\n",
      "    \n",
      "    no_progress()\n",
      "        Disable the progress bar from flushing to stdout.\n",
      "        \n",
      "        The completed progress bar is printed when a job is complete so as to demarcate a log file.\n",
      "    \n",
      "    parse_raw(setup, id=None, first_line_is_header=0)\n",
      "        Parse dataset using the parse setup structure.\n",
      "        \n",
      "        :param setup: Result of ``h2o.parse_setup()``\n",
      "        :param id: an id for the frame.\n",
      "        :param first_line_is_header: -1, 0, 1 if the first line is to be used as the header\n",
      "        \n",
      "        :returns: an :class:`H2OFrame` object.\n",
      "    \n",
      "    parse_setup(raw_frames, destination_frame=None, header=0, separator=None, column_names=None, column_types=None, na_strings=None, skipped_columns=None)\n",
      "        Retrieve H2O's best guess as to what the structure of the data file is.\n",
      "        \n",
      "        During parse setup, the H2O cluster will make several guesses about the attributes of\n",
      "        the data. This method allows a user to perform corrective measures by updating the\n",
      "        returning dictionary from this method. This dictionary is then fed into `parse_raw` to\n",
      "        produce the H2OFrame instance.\n",
      "        \n",
      "        :param raw_frames: a collection of imported file frames\n",
      "        :param destination_frame: The unique hex key assigned to the imported file. If none is given, a key will\n",
      "            automatically be generated.\n",
      "        :param header: -1 means the first line is data, 0 means guess, 1 means first line is header.\n",
      "        :param separator: The field separator character. Values on each line of the file are separated by\n",
      "            this character. If not provided, the parser will automatically detect the separator.\n",
      "        :param column_names: A list of column names for the file. If skipped_columns are specified, only list column names\n",
      "             of columns that are not skipped.\n",
      "        :param column_types: A list of types or a dictionary of column names to types to specify whether columns\n",
      "            should be forced to a certain type upon import parsing. If a list, the types for elements that are\n",
      "            one will be guessed. If skipped_columns are specified, only list column types of columns that are not skipped.\n",
      "            The possible types a column may have are:\n",
      "        \n",
      "            - \"unknown\" - this will force the column to be parsed as all NA\n",
      "            - \"uuid\"    - the values in the column must be true UUID or will be parsed as NA\n",
      "            - \"string\"  - force the column to be parsed as a string\n",
      "            - \"numeric\" - force the column to be parsed as numeric. H2O will handle the compression of the numeric\n",
      "              data in the optimal manner.\n",
      "            - \"enum\"    - force the column to be parsed as a categorical column.\n",
      "            - \"time\"    - force the column to be parsed as a time column. H2O will attempt to parse the following\n",
      "              list of date time formats: (date) \"yyyy-MM-dd\", \"yyyy MM dd\", \"dd-MMM-yy\", \"dd MMM yy\", (time)\n",
      "              \"HH:mm:ss\", \"HH:mm:ss:SSS\", \"HH:mm:ss:SSSnnnnnn\", \"HH.mm.ss\" \"HH.mm.ss.SSS\", \"HH.mm.ss.SSSnnnnnn\".\n",
      "              Times can also contain \"AM\" or \"PM\".\n",
      "        \n",
      "        :param na_strings: A list of strings, or a list of lists of strings (one list per column), or a dictionary\n",
      "            of column names to strings which are to be interpreted as missing values.\n",
      "        :param skipped_columns: an integer lists of column indices to skip and not parsed into the final frame from the import file.\n",
      "        \n",
      "        :returns: a dictionary containing parse parameters guessed by the H2O backend.\n",
      "    \n",
      "    rapids(expr)\n",
      "        Execute a Rapids expression.\n",
      "        \n",
      "        :param expr: The rapids expression (ascii string).\n",
      "        \n",
      "        :returns: The JSON response (as a python dictionary) of the Rapids execution.\n",
      "    \n",
      "    remove(x)\n",
      "        Remove object(s) from H2O.\n",
      "        \n",
      "        :param x: H2OFrame, H2OEstimator, or string, or a list of those things: the object(s) or unique id(s)\n",
      "            pointing to the object(s) to be removed.\n",
      "    \n",
      "    remove_all()\n",
      "        Remove all objects from H2O.\n",
      "    \n",
      "    save_model(model, path='', force=False)\n",
      "        Save an H2O Model object to disk. (Note that ensemble binary models can now be saved using this method.)\n",
      "        \n",
      "        :param model: The model object to save.\n",
      "        :param path: a path to save the model at (hdfs, s3, local)\n",
      "        :param force: if True overwrite destination directory in case it exists, or throw exception if set to False.\n",
      "        \n",
      "        :returns: the path of the saved model\n",
      "        \n",
      "        :examples:\n",
      "            >>> path = h2o.save_model(my_model, dir=my_path)\n",
      "    \n",
      "    set_timezone(*args, **kwargs)\n",
      "        Deprecated, set ``h2o.cluster().timezone`` instead.\n",
      "    \n",
      "    show_progress()\n",
      "        Enable the progress bar (it is enabled by default).\n",
      "    \n",
      "    shutdown(*args, **kwargs)\n",
      "        Deprecated, use ``h2o.cluster().shutdown()``.\n",
      "    \n",
      "    upload_custom_metric(func, func_file='metrics.py', func_name=None, class_name=None, source_provider=None)\n",
      "        Upload given metrics function into H2O cluster.\n",
      "        \n",
      "        The metrics can have different representation:\n",
      "          - method\n",
      "          - class: needs to inherit from water.udf.CFunc2 and implement method apply(actual, predict)\n",
      "          returning double\n",
      "          - string: the same as in class case, but the class is given as a string\n",
      "        \n",
      "        :param func:  metrics representation: string, class, function\n",
      "        :param func_file:  internal name of file to save given metrics representation\n",
      "        :param func_name:  name for h2o key under which the given metric is saved\n",
      "        :param class_name: name of class wrapping the metrics function\n",
      "        :param source_provider: a function which provides a source code for given function\n",
      "        :return: reference to uploaded metrics function\n",
      "    \n",
      "    upload_file(path, destination_frame=None, header=0, sep=None, col_names=None, col_types=None, na_strings=None, skipped_columns=None)\n",
      "        Upload a dataset from the provided local path to the H2O cluster.\n",
      "        \n",
      "        Does a single-threaded push to H2O. Also see :meth:`import_file`.\n",
      "        \n",
      "        :param path: A path specifying the location of the data to upload.\n",
      "        :param destination_frame:  The unique hex key assigned to the imported file. If none is given, a key will\n",
      "            be automatically generated.\n",
      "        :param header: -1 means the first line is data, 0 means guess, 1 means first line is header.\n",
      "        :param sep: The field separator character. Values on each line of the file are separated by\n",
      "            this character. If not provided, the parser will automatically detect the separator.\n",
      "        :param col_names: A list of column names for the file.\n",
      "        :param col_types: A list of types or a dictionary of column names to types to specify whether columns\n",
      "            should be forced to a certain type upon import parsing. If a list, the types for elements that are\n",
      "            one will be guessed. The possible types a column may have are:\n",
      "        \n",
      "            - \"unknown\" - this will force the column to be parsed as all NA\n",
      "            - \"uuid\"    - the values in the column must be true UUID or will be parsed as NA\n",
      "            - \"string\"  - force the column to be parsed as a string\n",
      "            - \"numeric\" - force the column to be parsed as numeric. H2O will handle the compression of the numeric\n",
      "              data in the optimal manner.\n",
      "            - \"enum\"    - force the column to be parsed as a categorical column.\n",
      "            - \"time\"    - force the column to be parsed as a time column. H2O will attempt to parse the following\n",
      "              list of date time formats: (date) \"yyyy-MM-dd\", \"yyyy MM dd\", \"dd-MMM-yy\", \"dd MMM yy\", (time)\n",
      "              \"HH:mm:ss\", \"HH:mm:ss:SSS\", \"HH:mm:ss:SSSnnnnnn\", \"HH.mm.ss\" \"HH.mm.ss.SSS\", \"HH.mm.ss.SSSnnnnnn\".\n",
      "              Times can also contain \"AM\" or \"PM\".\n",
      "        :param na_strings: A list of strings, or a list of lists of strings (one list per column), or a dictionary\n",
      "            of column names to strings which are to be interpreted as missing values.\n",
      "        :param skipped_columns: an integer lists of column indices to skip and not parsed into the final frame from the import file.\n",
      "        \n",
      "        :returns: a new :class:`H2OFrame` instance.\n",
      "        \n",
      "        :examples:\n",
      "            >>> frame = h2o.upload_file(\"/path/to/local/data\")\n",
      "\n",
      "DATA\n",
      "    __all__ = ('connect', 'init', 'api', 'connection', 'upload_file', 'laz...\n",
      "    __buildinfo__ = \"versionFromGradle='3.22.1',projectVersion='3.22....il...\n",
      "\n",
      "VERSION\n",
      "    3.22.1.3\n",
      "\n",
      "FILE\n",
      "    /Users/bear/anaconda/lib/python3.6/site-packages/h2o/__init__.py\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "help(h2o)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "help() can be used on H2O functions and models. Jupyter's builtin shift-tab functionality also works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class H2OGradientBoostingEstimator in module h2o.estimators.gbm:\n",
      "\n",
      "class H2OGradientBoostingEstimator(h2o.estimators.estimator_base.H2OEstimator)\n",
      " |  Gradient Boosting Machine\n",
      " |  \n",
      " |  Builds gradient boosted trees on a parsed data set, for regression or classification.\n",
      " |  The default distribution function will guess the model type based on the response column type.\n",
      " |  Otherwise, the response column must be an enum for \"bernoulli\" or \"multinomial\", and numeric\n",
      " |  for all other distributions.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      H2OGradientBoostingEstimator\n",
      " |      h2o.estimators.estimator_base.H2OEstimator\n",
      " |      h2o.model.model_base.ModelBase\n",
      " |      h2o.utils.backward_compatibility.BackwardsCompatibleBase\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, **kwargs)\n",
      " |      Construct a new model instance.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  balance_classes\n",
      " |      Balance training data class counts via over/under-sampling (for imbalanced data).\n",
      " |      \n",
      " |      Type: ``bool``  (default: ``False``).\n",
      " |  \n",
      " |  build_tree_one_node\n",
      " |      Run on one node only; no network overhead but fewer cpus used.  Suitable for small datasets.\n",
      " |      \n",
      " |      Type: ``bool``  (default: ``False``).\n",
      " |  \n",
      " |  calibrate_model\n",
      " |      Use Platt Scaling to calculate calibrated class probabilities. Calibration can provide more accurate estimates\n",
      " |      of class probabilities.\n",
      " |      \n",
      " |      Type: ``bool``  (default: ``False``).\n",
      " |  \n",
      " |  calibration_frame\n",
      " |      Calibration frame for Platt Scaling\n",
      " |      \n",
      " |      Type: ``H2OFrame``.\n",
      " |  \n",
      " |  categorical_encoding\n",
      " |      Encoding scheme for categorical features\n",
      " |      \n",
      " |      One of: ``\"auto\"``, ``\"enum\"``, ``\"one_hot_internal\"``, ``\"one_hot_explicit\"``, ``\"binary\"``, ``\"eigen\"``,\n",
      " |      ``\"label_encoder\"``, ``\"sort_by_response\"``, ``\"enum_limited\"``  (default: ``\"auto\"``).\n",
      " |  \n",
      " |  checkpoint\n",
      " |      Model checkpoint to resume training with.\n",
      " |      \n",
      " |      Type: ``str``.\n",
      " |  \n",
      " |  class_sampling_factors\n",
      " |      Desired over/under-sampling ratios per class (in lexicographic order). If not specified, sampling factors will\n",
      " |      be automatically computed to obtain class balance during training. Requires balance_classes.\n",
      " |      \n",
      " |      Type: ``List[float]``.\n",
      " |  \n",
      " |  col_sample_rate\n",
      " |      Column sample rate (from 0.0 to 1.0)\n",
      " |      \n",
      " |      Type: ``float``  (default: ``1``).\n",
      " |  \n",
      " |  col_sample_rate_change_per_level\n",
      " |      Relative change of the column sampling rate for every level (must be > 0.0 and <= 2.0)\n",
      " |      \n",
      " |      Type: ``float``  (default: ``1``).\n",
      " |  \n",
      " |  col_sample_rate_per_tree\n",
      " |      Column sample rate per tree (from 0.0 to 1.0)\n",
      " |      \n",
      " |      Type: ``float``  (default: ``1``).\n",
      " |  \n",
      " |  custom_metric_func\n",
      " |      Reference to custom evaluation function, format: `language:keyName=funcName`\n",
      " |      \n",
      " |      Type: ``str``.\n",
      " |  \n",
      " |  distribution\n",
      " |      Distribution function\n",
      " |      \n",
      " |      One of: ``\"auto\"``, ``\"bernoulli\"``, ``\"quasibinomial\"``, ``\"multinomial\"``, ``\"gaussian\"``, ``\"poisson\"``,\n",
      " |      ``\"gamma\"``, ``\"tweedie\"``, ``\"laplace\"``, ``\"quantile\"``, ``\"huber\"``  (default: ``\"auto\"``).\n",
      " |  \n",
      " |  export_checkpoints_dir\n",
      " |      Automatically export generated models to this directory.\n",
      " |      \n",
      " |      Type: ``str``.\n",
      " |  \n",
      " |  fold_assignment\n",
      " |      Cross-validation fold assignment scheme, if fold_column is not specified. The 'Stratified' option will stratify\n",
      " |      the folds based on the response variable, for classification problems.\n",
      " |      \n",
      " |      One of: ``\"auto\"``, ``\"random\"``, ``\"modulo\"``, ``\"stratified\"``  (default: ``\"auto\"``).\n",
      " |  \n",
      " |  fold_column\n",
      " |      Column with cross-validation fold index assignment per observation.\n",
      " |      \n",
      " |      Type: ``str``.\n",
      " |  \n",
      " |  histogram_type\n",
      " |      What type of histogram to use for finding optimal split points\n",
      " |      \n",
      " |      One of: ``\"auto\"``, ``\"uniform_adaptive\"``, ``\"random\"``, ``\"quantiles_global\"``, ``\"round_robin\"``  (default:\n",
      " |      ``\"auto\"``).\n",
      " |  \n",
      " |  huber_alpha\n",
      " |      Desired quantile for Huber/M-regression (threshold between quadratic and linear loss, must be between 0 and 1).\n",
      " |      \n",
      " |      Type: ``float``  (default: ``0.9``).\n",
      " |  \n",
      " |  ignore_const_cols\n",
      " |      Ignore constant columns.\n",
      " |      \n",
      " |      Type: ``bool``  (default: ``True``).\n",
      " |  \n",
      " |  ignored_columns\n",
      " |      Names of columns to ignore for training.\n",
      " |      \n",
      " |      Type: ``List[str]``.\n",
      " |  \n",
      " |  keep_cross_validation_fold_assignment\n",
      " |      Whether to keep the cross-validation fold assignment.\n",
      " |      \n",
      " |      Type: ``bool``  (default: ``False``).\n",
      " |  \n",
      " |  keep_cross_validation_models\n",
      " |      Whether to keep the cross-validation models.\n",
      " |      \n",
      " |      Type: ``bool``  (default: ``True``).\n",
      " |  \n",
      " |  keep_cross_validation_predictions\n",
      " |      Whether to keep the predictions of the cross-validation models.\n",
      " |      \n",
      " |      Type: ``bool``  (default: ``False``).\n",
      " |  \n",
      " |  learn_rate\n",
      " |      Learning rate (from 0.0 to 1.0)\n",
      " |      \n",
      " |      Type: ``float``  (default: ``0.1``).\n",
      " |  \n",
      " |  learn_rate_annealing\n",
      " |      Scale the learning rate by this factor after each tree (e.g., 0.99 or 0.999)\n",
      " |      \n",
      " |      Type: ``float``  (default: ``1``).\n",
      " |  \n",
      " |  max_abs_leafnode_pred\n",
      " |      Maximum absolute value of a leaf node prediction\n",
      " |      \n",
      " |      Type: ``float``  (default: ``1.797693135e+308``).\n",
      " |  \n",
      " |  max_after_balance_size\n",
      " |      Maximum relative size of the training data after balancing class counts (can be less than 1.0). Requires\n",
      " |      balance_classes.\n",
      " |      \n",
      " |      Type: ``float``  (default: ``5``).\n",
      " |  \n",
      " |  max_confusion_matrix_size\n",
      " |      [Deprecated] Maximum size (# classes) for confusion matrices to be printed in the Logs\n",
      " |      \n",
      " |      Type: ``int``  (default: ``20``).\n",
      " |  \n",
      " |  max_depth\n",
      " |      Maximum tree depth.\n",
      " |      \n",
      " |      Type: ``int``  (default: ``5``).\n",
      " |  \n",
      " |  max_hit_ratio_k\n",
      " |      Max. number (top K) of predictions to use for hit ratio computation (for multi-class only, 0 to disable)\n",
      " |      \n",
      " |      Type: ``int``  (default: ``0``).\n",
      " |  \n",
      " |  max_runtime_secs\n",
      " |      Maximum allowed runtime in seconds for model training. Use 0 to disable.\n",
      " |      \n",
      " |      Type: ``float``  (default: ``0``).\n",
      " |  \n",
      " |  min_rows\n",
      " |      Fewest allowed (weighted) observations in a leaf.\n",
      " |      \n",
      " |      Type: ``float``  (default: ``10``).\n",
      " |  \n",
      " |  min_split_improvement\n",
      " |      Minimum relative improvement in squared error reduction for a split to happen\n",
      " |      \n",
      " |      Type: ``float``  (default: ``1e-05``).\n",
      " |  \n",
      " |  monotone_constraints\n",
      " |      A mapping representing monotonic constraints. Use +1 to enforce an increasing constraint and -1 to specify a\n",
      " |      decreasing constraint.\n",
      " |      \n",
      " |      Type: ``dict``.\n",
      " |  \n",
      " |  nbins\n",
      " |      For numerical columns (real/int), build a histogram of (at least) this many bins, then split at the best point\n",
      " |      \n",
      " |      Type: ``int``  (default: ``20``).\n",
      " |  \n",
      " |  nbins_cats\n",
      " |      For categorical columns (factors), build a histogram of this many bins, then split at the best point. Higher\n",
      " |      values can lead to more overfitting.\n",
      " |      \n",
      " |      Type: ``int``  (default: ``1024``).\n",
      " |  \n",
      " |  nbins_top_level\n",
      " |      For numerical columns (real/int), build a histogram of (at most) this many bins at the root level, then decrease\n",
      " |      by factor of two per level\n",
      " |      \n",
      " |      Type: ``int``  (default: ``1024``).\n",
      " |  \n",
      " |  nfolds\n",
      " |      Number of folds for K-fold cross-validation (0 to disable or >= 2).\n",
      " |      \n",
      " |      Type: ``int``  (default: ``0``).\n",
      " |  \n",
      " |  ntrees\n",
      " |      Number of trees.\n",
      " |      \n",
      " |      Type: ``int``  (default: ``50``).\n",
      " |  \n",
      " |  offset_column\n",
      " |      Offset column. This will be added to the combination of columns before applying the link function.\n",
      " |      \n",
      " |      Type: ``str``.\n",
      " |  \n",
      " |  pred_noise_bandwidth\n",
      " |      Bandwidth (sigma) of Gaussian multiplicative noise ~N(1,sigma) for tree node predictions\n",
      " |      \n",
      " |      Type: ``float``  (default: ``0``).\n",
      " |  \n",
      " |  quantile_alpha\n",
      " |      Desired quantile for Quantile regression, must be between 0 and 1.\n",
      " |      \n",
      " |      Type: ``float``  (default: ``0.5``).\n",
      " |  \n",
      " |  r2_stopping\n",
      " |      r2_stopping is no longer supported and will be ignored if set - please use stopping_rounds, stopping_metric and\n",
      " |      stopping_tolerance instead. Previous version of H2O would stop making trees when the R^2 metric equals or\n",
      " |      exceeds this\n",
      " |      \n",
      " |      Type: ``float``  (default: ``1.797693135e+308``).\n",
      " |  \n",
      " |  response_column\n",
      " |      Response variable column.\n",
      " |      \n",
      " |      Type: ``str``.\n",
      " |  \n",
      " |  sample_rate\n",
      " |      Row sample rate per tree (from 0.0 to 1.0)\n",
      " |      \n",
      " |      Type: ``float``  (default: ``1``).\n",
      " |  \n",
      " |  sample_rate_per_class\n",
      " |      A list of row sample rates per class (relative fraction for each class, from 0.0 to 1.0), for each tree\n",
      " |      \n",
      " |      Type: ``List[float]``.\n",
      " |  \n",
      " |  score_each_iteration\n",
      " |      Whether to score during each iteration of model training.\n",
      " |      \n",
      " |      Type: ``bool``  (default: ``False``).\n",
      " |  \n",
      " |  score_tree_interval\n",
      " |      Score the model after every so many trees. Disabled if set to 0.\n",
      " |      \n",
      " |      Type: ``int``  (default: ``0``).\n",
      " |  \n",
      " |  seed\n",
      " |      Seed for pseudo random number generator (if applicable)\n",
      " |      \n",
      " |      Type: ``int``  (default: ``-1``).\n",
      " |  \n",
      " |  stopping_metric\n",
      " |      Metric to use for early stopping (AUTO: logloss for classification, deviance for regression)\n",
      " |      \n",
      " |      One of: ``\"auto\"``, ``\"deviance\"``, ``\"logloss\"``, ``\"mse\"``, ``\"rmse\"``, ``\"mae\"``, ``\"rmsle\"``, ``\"auc\"``,\n",
      " |      ``\"lift_top_group\"``, ``\"misclassification\"``, ``\"mean_per_class_error\"``, ``\"custom\"``, ``\"custom_increasing\"``\n",
      " |      (default: ``\"auto\"``).\n",
      " |  \n",
      " |  stopping_rounds\n",
      " |      Early stopping based on convergence of stopping_metric. Stop if simple moving average of length k of the\n",
      " |      stopping_metric does not improve for k:=stopping_rounds scoring events (0 to disable)\n",
      " |      \n",
      " |      Type: ``int``  (default: ``0``).\n",
      " |  \n",
      " |  stopping_tolerance\n",
      " |      Relative tolerance for metric-based stopping criterion (stop if relative improvement is not at least this much)\n",
      " |      \n",
      " |      Type: ``float``  (default: ``0.001``).\n",
      " |  \n",
      " |  training_frame\n",
      " |      Id of the training data frame.\n",
      " |      \n",
      " |      Type: ``H2OFrame``.\n",
      " |  \n",
      " |  tweedie_power\n",
      " |      Tweedie power for Tweedie regression, must be between 1 and 2.\n",
      " |      \n",
      " |      Type: ``float``  (default: ``1.5``).\n",
      " |  \n",
      " |  validation_frame\n",
      " |      Id of the validation data frame.\n",
      " |      \n",
      " |      Type: ``H2OFrame``.\n",
      " |  \n",
      " |  weights_column\n",
      " |      Column with observation weights. Giving some observation a weight of zero is equivalent to excluding it from the\n",
      " |      dataset; giving an observation a relative weight of 2 is equivalent to repeating that row twice. Negative\n",
      " |      weights are not allowed. Note: Weights are per-row observation weights and do not increase the size of the data\n",
      " |      frame. This is typically the number of times a row is repeated, but non-integer values are supported as well.\n",
      " |      During training, rows with higher weights matter more, due to the larger loss function pre-factor.\n",
      " |      \n",
      " |      Type: ``str``.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  algo = 'gbm'\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from h2o.estimators.estimator_base.H2OEstimator:\n",
      " |  \n",
      " |  convert_H2OXGBoostParams_2_XGBoostParams(self)\n",
      " |      In order to use convert_H2OXGBoostParams_2_XGBoostParams and convert_H2OFrame_2_DMatrix, you must import\n",
      " |      the following toolboxes: xgboost, pandas, numpy and scipy.sparse.\n",
      " |      \n",
      " |      Given an H2OXGBoost model, this method will generate the corresponding parameters that should be used by\n",
      " |      native XGBoost in order to give exactly the same result, assuming that the same dataset\n",
      " |      (derived from h2oFrame) is used to train the native XGBoost model.\n",
      " |      \n",
      " |      Follow the steps below to compare H2OXGBoost and native XGBoost:\n",
      " |      \n",
      " |      1. Train the H2OXGBoost model with H2OFrame trainFile and generate a prediction:\n",
      " |      h2oModelD = H2OXGBoostEstimator(**h2oParamsD) # parameters specified as a dict()\n",
      " |      h2oModelD.train(x=myX, y=y, training_frame=trainFile) # train with H2OFrame trainFile\n",
      " |      h2oPredict = h2oPredictD = h2oModelD.predict(trainFile)\n",
      " |      \n",
      " |      2. Derive the DMatrix from H2OFrame:\n",
      " |      nativeDMatrix = trainFile.convert_H2OFrame_2_DMatrix(myX, y, h2oModelD)\n",
      " |      \n",
      " |      3. Derive the parameters for native XGBoost:\n",
      " |      nativeParams = h2oModelD.convert_H2OXGBoostParams_2_XGBoostParams()\n",
      " |      \n",
      " |      4. Train your native XGBoost model and generate a prediction:\n",
      " |      nativeModel = xgb.train(params=nativeParams[0], dtrain=nativeDMatrix, num_boost_round=nativeParams[1])\n",
      " |      nativePredict = nativeModel.predict(data=nativeDMatrix, ntree_limit=nativeParams[1].\n",
      " |      \n",
      " |      5. Compare the predictions h2oPredict from H2OXGBoost, nativePredict from native XGBoost.\n",
      " |      \n",
      " |      :return: nativeParams, num_boost_round\n",
      " |  \n",
      " |  fit(self, X, y=None, **params)\n",
      " |      Fit an H2O model as part of a scikit-learn pipeline or grid search.\n",
      " |      \n",
      " |      A warning will be issued if a caller other than sklearn attempts to use this method.\n",
      " |      \n",
      " |      :param H2OFrame X: An H2OFrame consisting of the predictor variables.\n",
      " |      :param H2OFrame y: An H2OFrame consisting of the response variable.\n",
      " |      :param params: Extra arguments.\n",
      " |      :returns: The current instance of H2OEstimator for method chaining.\n",
      " |  \n",
      " |  get_params(self, deep=True)\n",
      " |      Obtain parameters for this estimator.\n",
      " |      \n",
      " |      Used primarily for sklearn Pipelines and sklearn grid search.\n",
      " |      \n",
      " |      :param deep: If True, return parameters of all sub-objects that are estimators.\n",
      " |      \n",
      " |      :returns: A dict of parameters\n",
      " |  \n",
      " |  join(self)\n",
      " |      Wait until job's completion.\n",
      " |  \n",
      " |  set_params(self, **parms)\n",
      " |      Used by sklearn for updating parameters during grid search.\n",
      " |      \n",
      " |      :param parms: A dictionary of parameters that will be set on this model.\n",
      " |      :returns: self, the current estimator object with the parameters all set as desired.\n",
      " |  \n",
      " |  start(self, x, y=None, training_frame=None, offset_column=None, fold_column=None, weights_column=None, validation_frame=None, **params)\n",
      " |      Train the model asynchronously (to block for results call :meth:`join`).\n",
      " |      \n",
      " |      :param x: A list of column names or indices indicating the predictor columns.\n",
      " |      :param y: An index or a column name indicating the response column.\n",
      " |      :param H2OFrame training_frame: The H2OFrame having the columns indicated by x and y (as well as any\n",
      " |          additional columns specified by fold, offset, and weights).\n",
      " |      :param offset_column: The name or index of the column in training_frame that holds the offsets.\n",
      " |      :param fold_column: The name or index of the column in training_frame that holds the per-row fold\n",
      " |          assignments.\n",
      " |      :param weights_column: The name or index of the column in training_frame that holds the per-row weights.\n",
      " |      :param validation_frame: H2OFrame with validation data to be scored on while training.\n",
      " |  \n",
      " |  train(self, x=None, y=None, training_frame=None, offset_column=None, fold_column=None, weights_column=None, validation_frame=None, max_runtime_secs=None, ignored_columns=None, model_id=None, verbose=False)\n",
      " |      Train the H2O model.\n",
      " |      \n",
      " |      :param x: A list of column names or indices indicating the predictor columns.\n",
      " |      :param y: An index or a column name indicating the response column.\n",
      " |      :param H2OFrame training_frame: The H2OFrame having the columns indicated by x and y (as well as any\n",
      " |          additional columns specified by fold, offset, and weights).\n",
      " |      :param offset_column: The name or index of the column in training_frame that holds the offsets.\n",
      " |      :param fold_column: The name or index of the column in training_frame that holds the per-row fold\n",
      " |          assignments.\n",
      " |      :param weights_column: The name or index of the column in training_frame that holds the per-row weights.\n",
      " |      :param validation_frame: H2OFrame with validation data to be scored on while training.\n",
      " |      :param float max_runtime_secs: Maximum allowed runtime in seconds for model training. Use 0 to disable.\n",
      " |      :param bool verbose: Print scoring history to stdout. Defaults to False.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Static methods inherited from h2o.estimators.estimator_base.H2OEstimator:\n",
      " |  \n",
      " |  mixin(obj, cls)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from h2o.model.model_base.ModelBase:\n",
      " |  \n",
      " |  __repr__(self)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  aic(self, train=False, valid=False, xval=False)\n",
      " |      Get the AIC (Akaike Information Criterium).\n",
      " |      \n",
      " |      If all are False (default), then return the training metric value.\n",
      " |      If more than one options is set to True, then return a dictionary of metrics where the keys are \"train\",\n",
      " |      \"valid\", and \"xval\".\n",
      " |      \n",
      " |      :param bool train: If train is True, then return the AIC value for the training data.\n",
      " |      :param bool valid: If valid is True, then return the AIC value for the validation data.\n",
      " |      :param bool xval:  If xval is True, then return the AIC value for the validation data.\n",
      " |      \n",
      " |      :returns: The AIC.\n",
      " |  \n",
      " |  auc(self, train=False, valid=False, xval=False)\n",
      " |      Get the AUC (Area Under Curve).\n",
      " |      \n",
      " |      If all are False (default), then return the training metric value.\n",
      " |      If more than one options is set to True, then return a dictionary of metrics where the keys are \"train\",\n",
      " |      \"valid\", and \"xval\".\n",
      " |      \n",
      " |      :param bool train: If train is True, then return the AUC value for the training data.\n",
      " |      :param bool valid: If valid is True, then return the AUC value for the validation data.\n",
      " |      :param bool xval:  If xval is True, then return the AUC value for the validation data.\n",
      " |      \n",
      " |      :returns: The AUC.\n",
      " |  \n",
      " |  biases(self, vector_id=0)\n",
      " |      Return the frame for the respective bias vector.\n",
      " |      \n",
      " |      :param: vector_id: an integer, ranging from 0 to number of layers, that specifies the bias vector to return.\n",
      " |      \n",
      " |      :returns: an H2OFrame which represents the bias vector identified by vector_id\n",
      " |  \n",
      " |  catoffsets(self)\n",
      " |      Categorical offsets for one-hot encoding.\n",
      " |  \n",
      " |  coef(self)\n",
      " |      Return the coefficients which can be applied to the non-standardized data.\n",
      " |      \n",
      " |      Note: standardize = True by default, if set to False then coef() return the coefficients which are fit directly.\n",
      " |  \n",
      " |  coef_norm(self)\n",
      " |      Return coefficients fitted on the standardized data (requires standardize = True, which is on by default).\n",
      " |      \n",
      " |      These coefficients can be used to evaluate variable importance.\n",
      " |  \n",
      " |  cross_validation_fold_assignment(self)\n",
      " |      Obtain the cross-validation fold assignment for all rows in the training data.\n",
      " |      \n",
      " |      :returns: H2OFrame\n",
      " |  \n",
      " |  cross_validation_holdout_predictions(self)\n",
      " |      Obtain the (out-of-sample) holdout predictions of all cross-validation models on the training data.\n",
      " |      \n",
      " |      This is equivalent to summing up all H2OFrames returned by cross_validation_predictions.\n",
      " |      \n",
      " |      :returns: H2OFrame\n",
      " |  \n",
      " |  cross_validation_metrics_summary(self)\n",
      " |      Retrieve Cross-Validation Metrics Summary.\n",
      " |      \n",
      " |      :returns: The cross-validation metrics summary as an H2OTwoDimTable\n",
      " |  \n",
      " |  cross_validation_models(self)\n",
      " |      Obtain a list of cross-validation models.\n",
      " |      \n",
      " |      :returns: list of H2OModel objects.\n",
      " |  \n",
      " |  cross_validation_predictions(self)\n",
      " |      Obtain the (out-of-sample) holdout predictions of all cross-validation models on their holdout data.\n",
      " |      \n",
      " |      Note that the predictions are expanded to the full number of rows of the training data, with 0 fill-in.\n",
      " |      \n",
      " |      :returns: list of H2OFrame objects.\n",
      " |  \n",
      " |  deepfeatures(self, test_data, layer)\n",
      " |      Return hidden layer details.\n",
      " |      \n",
      " |      :param test_data: Data to create a feature space on\n",
      " |      :param layer: 0 index hidden layer\n",
      " |  \n",
      " |  download_mojo(self, path='.', get_genmodel_jar=False, genmodel_name='')\n",
      " |      Download the model in MOJO format.\n",
      " |      \n",
      " |      :param path: the path where MOJO file should be saved.\n",
      " |      :param get_genmodel_jar: if True, then also download h2o-genmodel.jar and store it in folder ``path``.\n",
      " |      :param genmodel_name Custom name of genmodel jar\n",
      " |      :returns: name of the MOJO file written.\n",
      " |  \n",
      " |  download_pojo(self, path='', get_genmodel_jar=False, genmodel_name='')\n",
      " |      Download the POJO for this model to the directory specified by path.\n",
      " |      \n",
      " |      If path is an empty string, then dump the output to screen.\n",
      " |      \n",
      " |      :param path:  An absolute path to the directory where POJO should be saved.\n",
      " |      :param get_genmodel_jar: if True, then also download h2o-genmodel.jar and store it in folder ``path``.\n",
      " |      :param genmodel_name Custom name of genmodel jar\n",
      " |      :returns: name of the POJO file written.\n",
      " |  \n",
      " |  get_xval_models(self, key=None)\n",
      " |      Return a Model object.\n",
      " |      \n",
      " |      :param key: If None, return all cross-validated models; otherwise return the model that key points to.\n",
      " |      \n",
      " |      :returns: A model or list of models.\n",
      " |  \n",
      " |  gini(self, train=False, valid=False, xval=False)\n",
      " |      Get the Gini coefficient.\n",
      " |      \n",
      " |      If all are False (default), then return the training metric value.\n",
      " |      If more than one options is set to True, then return a dictionary of metrics where the keys are \"train\",\n",
      " |      \"valid\", and \"xval\"\n",
      " |      \n",
      " |      :param bool train: If train is True, then return the Gini Coefficient value for the training data.\n",
      " |      :param bool valid: If valid is True, then return the Gini Coefficient value for the validation data.\n",
      " |      :param bool xval:  If xval is True, then return the Gini Coefficient value for the cross validation data.\n",
      " |      \n",
      " |      :returns: The Gini Coefficient for this binomial model.\n",
      " |  \n",
      " |  is_cross_validated(self)\n",
      " |      Return True if the model was cross-validated.\n",
      " |  \n",
      " |  logloss(self, train=False, valid=False, xval=False)\n",
      " |      Get the Log Loss.\n",
      " |      \n",
      " |      If all are False (default), then return the training metric value.\n",
      " |      If more than one options is set to True, then return a dictionary of metrics where the keys are \"train\",\n",
      " |      \"valid\", and \"xval\".\n",
      " |      \n",
      " |      :param bool train: If train is True, then return the log loss value for the training data.\n",
      " |      :param bool valid: If valid is True, then return the log loss value for the validation data.\n",
      " |      :param bool xval:  If xval is True, then return the log loss value for the cross validation data.\n",
      " |      \n",
      " |      :returns: The log loss for this regression model.\n",
      " |  \n",
      " |  mae(self, train=False, valid=False, xval=False)\n",
      " |      Get the Mean Absolute Error.\n",
      " |      \n",
      " |      If all are False (default), then return the training metric value.\n",
      " |      If more than one options is set to True, then return a dictionary of metrics where the keys are \"train\",\n",
      " |      \"valid\", and \"xval\".\n",
      " |      \n",
      " |      :param bool train: If train is True, then return the MAE value for the training data.\n",
      " |      :param bool valid: If valid is True, then return the MAE value for the validation data.\n",
      " |      :param bool xval:  If xval is True, then return the MAE value for the cross validation data.\n",
      " |      \n",
      " |      :returns: The MAE for this regression model.\n",
      " |  \n",
      " |  mean_residual_deviance(self, train=False, valid=False, xval=False)\n",
      " |      Get the Mean Residual Deviances.\n",
      " |      \n",
      " |      If all are False (default), then return the training metric value.\n",
      " |      If more than one options is set to True, then return a dictionary of metrics where the keys are \"train\",\n",
      " |      \"valid\", and \"xval\".\n",
      " |      \n",
      " |      :param bool train: If train is True, then return the Mean Residual Deviance value for the training data.\n",
      " |      :param bool valid: If valid is True, then return the Mean Residual Deviance value for the validation data.\n",
      " |      :param bool xval:  If xval is True, then return the Mean Residual Deviance value for the cross validation data.\n",
      " |      \n",
      " |      :returns: The Mean Residual Deviance for this regression model.\n",
      " |  \n",
      " |  model_performance(self, test_data=None, train=False, valid=False, xval=False)\n",
      " |      Generate model metrics for this model on test_data.\n",
      " |      \n",
      " |      :param H2OFrame test_data: Data set for which model metrics shall be computed against. All three of train,\n",
      " |          valid and xval arguments are ignored if test_data is not None.\n",
      " |      :param bool train: Report the training metrics for the model.\n",
      " |      :param bool valid: Report the validation metrics for the model.\n",
      " |      :param bool xval: Report the cross-validation metrics for the model. If train and valid are True, then it\n",
      " |          defaults to True.\n",
      " |      \n",
      " |      :returns: An object of class H2OModelMetrics.\n",
      " |  \n",
      " |  mse(self, train=False, valid=False, xval=False)\n",
      " |      Get the Mean Square Error.\n",
      " |      \n",
      " |      If all are False (default), then return the training metric value.\n",
      " |      If more than one options is set to True, then return a dictionary of metrics where the keys are \"train\",\n",
      " |      \"valid\", and \"xval\".\n",
      " |      \n",
      " |      :param bool train: If train is True, then return the MSE value for the training data.\n",
      " |      :param bool valid: If valid is True, then return the MSE value for the validation data.\n",
      " |      :param bool xval:  If xval is True, then return the MSE value for the cross validation data.\n",
      " |      \n",
      " |      :returns: The MSE for this regression model.\n",
      " |  \n",
      " |  normmul(self)\n",
      " |      Normalization/Standardization multipliers for numeric predictors.\n",
      " |  \n",
      " |  normsub(self)\n",
      " |      Normalization/Standardization offsets for numeric predictors.\n",
      " |  \n",
      " |  null_degrees_of_freedom(self, train=False, valid=False, xval=False)\n",
      " |      Retreive the null degress of freedom if this model has the attribute, or None otherwise.\n",
      " |      \n",
      " |      :param bool train: Get the null dof for the training set. If both train and valid are False, then train is\n",
      " |          selected by default.\n",
      " |      :param bool valid: Get the null dof for the validation set. If both train and valid are True, then train is\n",
      " |          selected by default.\n",
      " |      \n",
      " |      :returns: Return the null dof, or None if it is not present.\n",
      " |  \n",
      " |  null_deviance(self, train=False, valid=False, xval=False)\n",
      " |      Retreive the null deviance if this model has the attribute, or None otherwise.\n",
      " |      \n",
      " |      :param bool train: Get the null deviance for the training set. If both train and valid are False, then train\n",
      " |          is selected by default.\n",
      " |      :param bool valid: Get the null deviance for the validation set. If both train and valid are True, then train\n",
      " |          is selected by default.\n",
      " |      \n",
      " |      :returns: Return the null deviance, or None if it is not present.\n",
      " |  \n",
      " |  partial_plot(self, data, cols, destination_key=None, nbins=20, weight_column=None, plot=True, plot_stddev=True, figsize=(7, 10), server=False, include_na=False, user_splits=None, save_to_file=None)\n",
      " |      Create partial dependence plot which gives a graphical depiction of the marginal effect of a variable on the\n",
      " |      response. The effect of a variable is measured in change in the mean response.\n",
      " |      \n",
      " |      :param H2OFrame data: An H2OFrame object used for scoring and constructing the plot.\n",
      " |      :param cols: Feature(s) for which partial dependence will be calculated.\n",
      " |      :param destination_key: An key reference to the created partial dependence tables in H2O.\n",
      " |      :param nbins: Number of bins used. For categorical columns make sure the number of bins exceed the level count. If you enable add_missing_NA, the returned length will be nbin+1.\n",
      " |      :param weight_column: A string denoting which column of data should be used as the weight column.\n",
      " |      :param plot: A boolean specifying whether to plot partial dependence table.\n",
      " |      :param plot_stddev: A boolean specifying whether to add std err to partial dependence plot.\n",
      " |      :param figsize: Dimension/size of the returning plots, adjust to fit your output cells.\n",
      " |      :param server: ?\n",
      " |      :param include_na: A boolean specifying whether missing value should be included in the Feature values.\n",
      " |      :param user_splits: a dictionary containing column names as key and user defined split values as value in a list.\n",
      " |      :param save_to_file Fully qualified name to an image file the resulting plot should be saved to, e.g. '/home/user/pdpplot.png'. The 'png' postfix might be omitted. If the file already exists, it will be overridden. Plot is only saved if plot = True.\n",
      " |      :returns: Plot and list of calculated mean response tables for each feature requested.\n",
      " |  \n",
      " |  pprint_coef(self)\n",
      " |      Pretty print the coefficents table (includes normalized coefficients).\n",
      " |  \n",
      " |  predict(self, test_data, custom_metric=None, custom_metric_func=None)\n",
      " |      Predict on a dataset.\n",
      " |      \n",
      " |      :param H2OFrame test_data: Data on which to make predictions.\n",
      " |      :param custom_metric:  custom evaluation function defined as class reference, the class get uploaded\n",
      " |      into cluster\n",
      " |      :param custom_metric_func: custom evaluation function reference, e.g, result of upload_custom_metric\n",
      " |      \n",
      " |      :returns: A new H2OFrame of predictions.\n",
      " |  \n",
      " |  predict_leaf_node_assignment(self, test_data, type='Path')\n",
      " |      Predict on a dataset and return the leaf node assignment (only for tree-based models).\n",
      " |      \n",
      " |      :param H2OFrame test_data: Data on which to make predictions.\n",
      " |      :param Enum type: How to identify the leaf node. Nodes can be either identified by a path from to the root node\n",
      " |      of the tree to the node or by H2O's internal node id. One of: ``\"Path\"``, ``\"Node_ID\"`` (default: ``\"Path\"``).\n",
      " |      \n",
      " |      :returns: A new H2OFrame of predictions.\n",
      " |  \n",
      " |  r2(self, train=False, valid=False, xval=False)\n",
      " |      Return the R squared for this regression model.\n",
      " |      \n",
      " |      Will return R^2 for GLM Models and will return NaN otherwise.\n",
      " |      \n",
      " |      The R^2 value is defined to be 1 - MSE/var, where var is computed as sigma*sigma.\n",
      " |      \n",
      " |      If all are False (default), then return the training metric value.\n",
      " |      If more than one options is set to True, then return a dictionary of metrics where the keys are \"train\",\n",
      " |      \"valid\", and \"xval\".\n",
      " |      \n",
      " |      :param bool train: If train is True, then return the R^2 value for the training data.\n",
      " |      :param bool valid: If valid is True, then return the R^2 value for the validation data.\n",
      " |      :param bool xval:  If xval is True, then return the R^2 value for the cross validation data.\n",
      " |      \n",
      " |      :returns: The R squared for this regression model.\n",
      " |  \n",
      " |  residual_degrees_of_freedom(self, train=False, valid=False, xval=False)\n",
      " |      Retreive the residual degress of freedom if this model has the attribute, or None otherwise.\n",
      " |      \n",
      " |      :param bool train: Get the residual dof for the training set. If both train and valid are False, then train\n",
      " |          is selected by default.\n",
      " |      :param bool valid: Get the residual dof for the validation set. If both train and valid are True, then train\n",
      " |          is selected by default.\n",
      " |      \n",
      " |      :returns: Return the residual dof, or None if it is not present.\n",
      " |  \n",
      " |  residual_deviance(self, train=False, valid=False, xval=None)\n",
      " |      Retreive the residual deviance if this model has the attribute, or None otherwise.\n",
      " |      \n",
      " |      :param bool train: Get the residual deviance for the training set. If both train and valid are False, then\n",
      " |          train is selected by default.\n",
      " |      :param bool valid: Get the residual deviance for the validation set. If both train and valid are True, then\n",
      " |          train is selected by default.\n",
      " |      \n",
      " |      :returns: Return the residual deviance, or None if it is not present.\n",
      " |  \n",
      " |  respmul(self)\n",
      " |      Normalization/Standardization multipliers for numeric response.\n",
      " |  \n",
      " |  respsub(self)\n",
      " |      Normalization/Standardization offsets for numeric response.\n",
      " |  \n",
      " |  rmse(self, train=False, valid=False, xval=False)\n",
      " |      Get the Root Mean Square Error.\n",
      " |      \n",
      " |      If all are False (default), then return the training metric value.\n",
      " |      If more than one options is set to True, then return a dictionary of metrics where the keys are \"train\",\n",
      " |      \"valid\", and \"xval\".\n",
      " |      \n",
      " |      :param bool train: If train is True, then return the RMSE value for the training data.\n",
      " |      :param bool valid: If valid is True, then return the RMSE value for the validation data.\n",
      " |      :param bool xval:  If xval is True, then return the RMSE value for the cross validation data.\n",
      " |      \n",
      " |      :returns: The RMSE for this regression model.\n",
      " |  \n",
      " |  rmsle(self, train=False, valid=False, xval=False)\n",
      " |      Get the Root Mean Squared Logarithmic Error.\n",
      " |      \n",
      " |      If all are False (default), then return the training metric value.\n",
      " |      If more than one options is set to True, then return a dictionary of metrics where the keys are \"train\",\n",
      " |      \"valid\", and \"xval\".\n",
      " |      \n",
      " |      :param bool train: If train is True, then return the RMSLE value for the training data.\n",
      " |      :param bool valid: If valid is True, then return the RMSLE value for the validation data.\n",
      " |      :param bool xval:  If xval is True, then return the RMSLE value for the cross validation data.\n",
      " |      \n",
      " |      :returns: The RMSLE for this regression model.\n",
      " |  \n",
      " |  rotation(self)\n",
      " |      Obtain the rotations (eigenvectors) for a PCA model\n",
      " |      \n",
      " |      :return: H2OFrame\n",
      " |  \n",
      " |  save_model_details(self, path='', force=False)\n",
      " |      Save Model Details of an H2O Model in JSON Format to disk.\n",
      " |      \n",
      " |      :param model: The model object to save.\n",
      " |      :param path: a path to save the model details at (hdfs, s3, local)\n",
      " |      :param force: if True overwrite destination directory in case it exists, or throw exception if set to False.\n",
      " |      \n",
      " |      :returns str: the path of the saved model details\n",
      " |  \n",
      " |  save_mojo(self, path='', force=False)\n",
      " |      Save an H2O Model as MOJO (Model Object, Optimized) to disk.\n",
      " |      \n",
      " |      :param model: The model object to save.\n",
      " |      :param path: a path to save the model at (hdfs, s3, local)\n",
      " |      :param force: if True overwrite destination directory in case it exists, or throw exception if set to False.\n",
      " |      \n",
      " |      :returns str: the path of the saved model\n",
      " |  \n",
      " |  score_history(self)\n",
      " |      DEPRECATED. Use :meth:`scoring_history` instead.\n",
      " |  \n",
      " |  scoring_history(self)\n",
      " |      Retrieve Model Score History.\n",
      " |      \n",
      " |      :returns: The score history as an H2OTwoDimTable or a Pandas DataFrame.\n",
      " |  \n",
      " |  show(self)\n",
      " |      Print innards of model, without regards to type.\n",
      " |  \n",
      " |  staged_predict_proba(self, test_data)\n",
      " |      Predict class probabilities at each stage of an H2O Model (only GBM models).\n",
      " |      \n",
      " |      The output structure is analogous to the output of function predict_leaf_node_assignment. For each tree t and\n",
      " |      class c there will be a column Tt.Cc (eg. T3.C1 for tree 3 and class 1). The value will be the corresponding\n",
      " |      predicted probability of this class by combining the raw contributions of trees T1.Cc,..,TtCc. Binomial models\n",
      " |      build the trees just for the first class and values in columns Tx.C1 thus correspond to the the probability p0.\n",
      " |      \n",
      " |      :param H2OFrame test_data: Data on which to make predictions.\n",
      " |      \n",
      " |      :returns: A new H2OFrame of staged predictions.\n",
      " |  \n",
      " |  std_coef_plot(self, num_of_features=None, server=False)\n",
      " |      Plot a GLM model\"s standardized coefficient magnitudes.\n",
      " |      \n",
      " |      :param num_of_features: the number of features shown in the plot.\n",
      " |      :param server: ?\n",
      " |      \n",
      " |      :returns: None.\n",
      " |  \n",
      " |  summary(self)\n",
      " |      Print a detailed summary of the model.\n",
      " |  \n",
      " |  varimp(self, use_pandas=False)\n",
      " |      Pretty print the variable importances, or return them in a list.\n",
      " |      \n",
      " |      :param use_pandas: If True, then the variable importances will be returned as a pandas data frame.\n",
      " |      \n",
      " |      :returns: A list or Pandas DataFrame.\n",
      " |  \n",
      " |  varimp_plot(self, num_of_features=None, server=False)\n",
      " |      Plot the variable importance for a trained model.\n",
      " |      \n",
      " |      :param num_of_features: the number of features shown in the plot (default is 10 or all if less than 10).\n",
      " |      :param server: ?\n",
      " |      \n",
      " |      :returns: None.\n",
      " |  \n",
      " |  weights(self, matrix_id=0)\n",
      " |      Return the frame for the respective weight matrix.\n",
      " |      \n",
      " |      :param: matrix_id: an integer, ranging from 0 to number of layers, that specifies the weight matrix to return.\n",
      " |      \n",
      " |      :returns: an H2OFrame which represents the weight matrix identified by matrix_id\n",
      " |  \n",
      " |  xval_keys(self)\n",
      " |      Return model keys for the cross-validated model.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from h2o.model.model_base.ModelBase:\n",
      " |  \n",
      " |  actual_params\n",
      " |      Dictionary of actual parameters of the model.\n",
      " |  \n",
      " |  default_params\n",
      " |      Dictionary of the default parameters of the model.\n",
      " |  \n",
      " |  end_time\n",
      " |      Timestamp (milliseconds since 1970) when the model training was ended.\n",
      " |  \n",
      " |  full_parameters\n",
      " |      Dictionary of the full specification of all parameters.\n",
      " |  \n",
      " |  have_mojo\n",
      " |      True, if export to MOJO is possible\n",
      " |  \n",
      " |  have_pojo\n",
      " |      True, if export to POJO is possible\n",
      " |  \n",
      " |  model_id\n",
      " |      Model identifier.\n",
      " |  \n",
      " |  params\n",
      " |      Get the parameters and the actual/default values only.\n",
      " |      \n",
      " |      :returns: A dictionary of parameters used to build this model.\n",
      " |  \n",
      " |  run_time\n",
      " |      Model training time in milliseconds\n",
      " |  \n",
      " |  start_time\n",
      " |      Timestamp (milliseconds since 1970) when the model training was started.\n",
      " |  \n",
      " |  type\n",
      " |      The type of model built: ``\"classifier\"`` or ``\"regressor\"`` or ``\"unsupervised\"``\n",
      " |  \n",
      " |  xvals\n",
      " |      Return a list of the cross-validated models.\n",
      " |      \n",
      " |      :returns: A list of models.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from h2o.utils.backward_compatibility.BackwardsCompatibleBase:\n",
      " |  \n",
      " |  __getattr__(self, item)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from h2o.utils.backward_compatibility.BackwardsCompatibleBase:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Help on function import_file in module h2o.h2o:\n",
      "\n",
      "import_file(path=None, destination_frame=None, parse=True, header=0, sep=None, col_names=None, col_types=None, na_strings=None, pattern=None, skipped_columns=None)\n",
      "    Import a dataset that is already on the cluster.\n",
      "    \n",
      "    The path to the data must be a valid path for each node in the H2O cluster. If some node in the H2O cluster\n",
      "    cannot see the file, then an exception will be thrown by the H2O cluster. Does a parallel/distributed\n",
      "    multi-threaded pull of the data. The main difference between this method and :func:`upload_file` is that\n",
      "    the latter works with local files, whereas this method imports remote files (i.e. files local to the server).\n",
      "    If you running H2O server on your own maching, then both methods behave the same.\n",
      "    \n",
      "    :param path: path(s) specifying the location of the data to import or a path to a directory of files to import\n",
      "    :param destination_frame: The unique hex key assigned to the imported file. If none is given, a key will be\n",
      "        automatically generated.\n",
      "    :param parse: If True, the file should be parsed after import. If False, then a list is returned containing the file path.\n",
      "    :param header: -1 means the first line is data, 0 means guess, 1 means first line is header.\n",
      "    :param sep: The field separator character. Values on each line of the file are separated by\n",
      "        this character. If not provided, the parser will automatically detect the separator.\n",
      "    :param col_names: A list of column names for the file.\n",
      "    :param col_types: A list of types or a dictionary of column names to types to specify whether columns\n",
      "        should be forced to a certain type upon import parsing. If a list, the types for elements that are\n",
      "        one will be guessed. The possible types a column may have are:\n",
      "    \n",
      "        - \"unknown\" - this will force the column to be parsed as all NA\n",
      "        - \"uuid\"    - the values in the column must be true UUID or will be parsed as NA\n",
      "        - \"string\"  - force the column to be parsed as a string\n",
      "        - \"numeric\" - force the column to be parsed as numeric. H2O will handle the compression of the numeric\n",
      "          data in the optimal manner.\n",
      "        - \"enum\"    - force the column to be parsed as a categorical column.\n",
      "        - \"time\"    - force the column to be parsed as a time column. H2O will attempt to parse the following\n",
      "          list of date time formats: (date) \"yyyy-MM-dd\", \"yyyy MM dd\", \"dd-MMM-yy\", \"dd MMM yy\", (time)\n",
      "          \"HH:mm:ss\", \"HH:mm:ss:SSS\", \"HH:mm:ss:SSSnnnnnn\", \"HH.mm.ss\" \"HH.mm.ss.SSS\", \"HH.mm.ss.SSSnnnnnn\".\n",
      "          Times can also contain \"AM\" or \"PM\".\n",
      "    :param na_strings: A list of strings, or a list of lists of strings (one list per column), or a dictionary\n",
      "        of column names to strings which are to be interpreted as missing values.\n",
      "    :param pattern: Character string containing a regular expression to match file(s) in the folder if `path` is a\n",
      "        directory.\n",
      "    :param skipped_columns: an integer list of column indices to skip and not parsed into the final frame from the import file.\n",
      "    \n",
      "    :returns: a new :class:`H2OFrame` instance.\n",
      "    \n",
      "    :examples:\n",
      "        >>> # Single file import\n",
      "        >>> iris = import_file(\"h2o-3/smalldata/iris.csv\")\n",
      "        >>> # Return all files in the folder iris/ matching the regex r\"iris_.*\\.csv\"\n",
      "        >>> iris_pattern = h2o.import_file(path = \"h2o-3/smalldata/iris\",\n",
      "        ...                                pattern = \"iris_.*\\.csv\")\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from h2o.estimators.gbm import H2OGradientBoostingEstimator\n",
    "from h2o.estimators.random_forest import H2ORandomForestEstimator\n",
    "help(H2OGradientBoostingEstimator)\n",
    "help(h2o.import_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## H2O GBM and RF\n",
    "\n",
    "While H2O Gradient Boosting Models and H2O Random Forest have many flexible parameters options, they were designed to be just as easy to use as the other supervised training methods in H2O. Early stopping, automatic data standardization and handling of categorical variables and missing values and adaptive learning rates (per weight) reduce the amount of parameters the user has to specify. Often, it's just the number and sizes of hidden layers, the number of epochs and the activation function and maybe some regularization techniques. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting started\n",
    "\n",
    "We begin by importing our data into H2OFrames, which operate similarly in function to pandas DataFrames but exist on the H2O cloud itself.  \n",
    "\n",
    "In this case, the H2O cluster is running on our laptops. Data files are imported by their relative locations to this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: || 100%\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "covtype_df = h2o.import_file(os.path.realpath(\"data/covtype.full.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We import the full covertype dataset (581k rows, 13 columns, 10 numerical, 3 categorical) and then split the data 3 ways:  \n",
    "  \n",
    "60% for training  \n",
    "20% for validation (hyper parameter tuning)  \n",
    "20% for final testing  \n",
    "\n",
    " We will train a data set on one set and use the others to test the validity of the model by ensuring that it can predict accurately on data the model has not been shown.  \n",
    " \n",
    " The second set will be used for validation most of the time.  \n",
    " \n",
    " The third set will be withheld until the end, to ensure that our validation accuracy is consistent with data we have never seen during the iterative process. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#split the data as described above\n",
    "train, valid, test = covtype_df.split_frame([0.6, 0.2], seed=1234)\n",
    "\n",
    "#Prepare predictors and response columns\n",
    "covtype_X = covtype_df.col_names[:-1]     #last column is Cover_Type, our desired response variable \n",
    "covtype_y = covtype_df.col_names[-1]    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The First Random Forest\n",
    "We build our first model with the following parameters\n",
    "\n",
    "**model_id:** Not required, but allows us to easily find our model in the [Flow](http://localhost:54321/) interface  \n",
    "**ntrees:** Maximum number of trees used by the random forest. Default value is 50. We can afford to increase this, as our early-stopping criterion will decide when the random forest is sufficiently accurate.  \n",
    "**stopping_rounds:** Stopping criterion described above. Stops fitting new trees when 2-tree rolling average is within 0.001 (default) of the two prior rolling averages. Can be thought of as a convergence setting.  \n",
    "**score_each_teration:** predict against training and validation for each tree. Default will skip several.  \n",
    "**seed:** set the randomization seed so we can reproduce results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rf_v1 = H2ORandomForestEstimator(\n",
    "    model_id=\"rf_covType_v1\",\n",
    "    ntrees=200,\n",
    "    stopping_rounds=2,\n",
    "    score_each_iteration=True,\n",
    "    seed=1000000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Construction\n",
    "H2O in Python is designed to be very similar in look and feel to to scikit-learn. Models are initialized individually with desired or default parameters and then trained on data.  \n",
    "\n",
    "**Note that the below example uses model.train() as opposed the traditional model.fit()**  \n",
    "This is because h2o-py takes column indices for the feature and response columns AND the whole data frame, while scikit-learn takes in a feature frame and a response frame.\n",
    "\n",
    "H2O supports model.fit() so that it can be incorporated into a scikit-learn pipeline, but we advise using train() in all other cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drf Model Build progress: || 100%\n"
     ]
    }
   ],
   "source": [
    "rf_v1.train(covtype_X, covtype_y, training_frame=train, validation_frame=valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the progress bar does not behave linearly. H2O estimates completion time initially based on the number of epochs specified. However, convergence can allow for early stops, in which case the bar jumps to 100%.\n",
    "\n",
    "We can view information about the model in [Flow](http://localhost:54321/) or within Python. To find more information in Flow, enter `getModel \"rf_covType_v1\"` into a cell and run in place pressing Ctrl-Enter. Alternatively, you can click on the Models tab, select List All Models, and click on the model named \"rf_covType_v1\" as specified in our model construction above.\n",
    "\n",
    "In Python, we can call the model itself to get an overview of its stats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Details\n",
      "=============\n",
      "H2ORandomForestEstimator :  Distributed Random Forest\n",
      "Model Key:  rf_covType_v1\n",
      "\n",
      "\n",
      "ModelMetricsMultinomial: drf\n",
      "** Reported on train data. **\n",
      "\n",
      "MSE: 0.056076839859494784\n",
      "RMSE: 0.23680548950456107\n",
      "LogLoss: 0.2384329935890688\n",
      "Mean Per-Class Error: 0.11102189346483596\n",
      "Confusion Matrix: Row labels: Actual class; Column labels: Predicted class\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>class_1</b></td>\n",
       "<td><b>class_2</b></td>\n",
       "<td><b>class_3</b></td>\n",
       "<td><b>class_4</b></td>\n",
       "<td><b>class_5</b></td>\n",
       "<td><b>class_6</b></td>\n",
       "<td><b>class_7</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>117176.0</td>\n",
       "<td>9534.0</td>\n",
       "<td>5.0</td>\n",
       "<td>0.0</td>\n",
       "<td>53.0</td>\n",
       "<td>11.0</td>\n",
       "<td>338.0</td>\n",
       "<td>0.0782035</td>\n",
       "<td>9,941 / 127,117</td></tr>\n",
       "<tr><td>5414.0</td>\n",
       "<td>164066.0</td>\n",
       "<td>321.0</td>\n",
       "<td>3.0</td>\n",
       "<td>240.0</td>\n",
       "<td>244.0</td>\n",
       "<td>50.0</td>\n",
       "<td>0.0368209</td>\n",
       "<td>6,272 / 170,338</td></tr>\n",
       "<tr><td>32.0</td>\n",
       "<td>413.0</td>\n",
       "<td>20370.0</td>\n",
       "<td>93.0</td>\n",
       "<td>22.0</td>\n",
       "<td>512.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0499953</td>\n",
       "<td>1,072 / 21,442</td></tr>\n",
       "<tr><td>0.0</td>\n",
       "<td>32.0</td>\n",
       "<td>178.0</td>\n",
       "<td>1390.0</td>\n",
       "<td>0.0</td>\n",
       "<td>58.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.1616405</td>\n",
       "<td>268 / 1,658</td></tr>\n",
       "<tr><td>93.0</td>\n",
       "<td>1386.0</td>\n",
       "<td>63.0</td>\n",
       "<td>0.0</td>\n",
       "<td>4161.0</td>\n",
       "<td>17.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.2725524</td>\n",
       "<td>1,559 / 5,720</td></tr>\n",
       "<tr><td>38.0</td>\n",
       "<td>368.0</td>\n",
       "<td>739.0</td>\n",
       "<td>42.0</td>\n",
       "<td>7.0</td>\n",
       "<td>9239.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.1144446</td>\n",
       "<td>1,194 / 10,433</td></tr>\n",
       "<tr><td>709.0</td>\n",
       "<td>70.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>2.0</td>\n",
       "<td>0.0</td>\n",
       "<td>11519.0</td>\n",
       "<td>0.0634959</td>\n",
       "<td>781 / 12,300</td></tr>\n",
       "<tr><td>123462.0</td>\n",
       "<td>175869.0</td>\n",
       "<td>21676.0</td>\n",
       "<td>1528.0</td>\n",
       "<td>4485.0</td>\n",
       "<td>10081.0</td>\n",
       "<td>11907.0</td>\n",
       "<td>0.0604198</td>\n",
       "<td>21,087 / 349,008</td></tr></table></div>"
      ],
      "text/plain": [
       "class_1    class_2    class_3    class_4    class_5    class_6    class_7    Error      Rate\n",
       "---------  ---------  ---------  ---------  ---------  ---------  ---------  ---------  ----------------\n",
       "117176     9534       5          0          53         11         338        0.0782035  9,941 / 127,117\n",
       "5414       164066     321        3          240        244        50         0.0368209  6,272 / 170,338\n",
       "32         413        20370      93         22         512        0          0.0499953  1,072 / 21,442\n",
       "0          32         178        1390       0          58         0          0.161641   268 / 1,658\n",
       "93         1386       63         0          4161       17         0          0.272552   1,559 / 5,720\n",
       "38         368        739        42         7          9239       0          0.114445   1,194 / 10,433\n",
       "709        70         0          0          2          0          11519      0.0634959  781 / 12,300\n",
       "123462     175869     21676      1528       4485       10081      11907      0.0604198  21,087 / 349,008"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-7 Hit Ratios: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>k</b></td>\n",
       "<td><b>hit_ratio</b></td></tr>\n",
       "<tr><td>1</td>\n",
       "<td>0.9395802</td></tr>\n",
       "<tr><td>2</td>\n",
       "<td>0.9962408</td></tr>\n",
       "<tr><td>3</td>\n",
       "<td>0.9982007</td></tr>\n",
       "<tr><td>4</td>\n",
       "<td>0.9982522</td></tr>\n",
       "<tr><td>5</td>\n",
       "<td>0.9982522</td></tr>\n",
       "<tr><td>6</td>\n",
       "<td>0.9982522</td></tr>\n",
       "<tr><td>7</td>\n",
       "<td>1.0</td></tr></table></div>"
      ],
      "text/plain": [
       "k    hit_ratio\n",
       "---  -----------\n",
       "1    0.93958\n",
       "2    0.996241\n",
       "3    0.998201\n",
       "4    0.998252\n",
       "5    0.998252\n",
       "6    0.998252\n",
       "7    1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ModelMetricsMultinomial: drf\n",
      "** Reported on validation data. **\n",
      "\n",
      "MSE: 0.053141408943200595\n",
      "RMSE: 0.23052420467968346\n",
      "LogLoss: 0.20030408050020734\n",
      "Mean Per-Class Error: 0.10251306792333845\n",
      "Confusion Matrix: Row labels: Actual class; Column labels: Predicted class\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>class_1</b></td>\n",
       "<td><b>class_2</b></td>\n",
       "<td><b>class_3</b></td>\n",
       "<td><b>class_4</b></td>\n",
       "<td><b>class_5</b></td>\n",
       "<td><b>class_6</b></td>\n",
       "<td><b>class_7</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>39403.0</td>\n",
       "<td>2998.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>15.0</td>\n",
       "<td>2.0</td>\n",
       "<td>82.0</td>\n",
       "<td>0.0728706</td>\n",
       "<td>3,097 / 42,500</td></tr>\n",
       "<tr><td>1589.0</td>\n",
       "<td>54529.0</td>\n",
       "<td>104.0</td>\n",
       "<td>0.0</td>\n",
       "<td>83.0</td>\n",
       "<td>60.0</td>\n",
       "<td>15.0</td>\n",
       "<td>0.0328308</td>\n",
       "<td>1,851 / 56,380</td></tr>\n",
       "<tr><td>0.0</td>\n",
       "<td>131.0</td>\n",
       "<td>6844.0</td>\n",
       "<td>30.0</td>\n",
       "<td>3.0</td>\n",
       "<td>135.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0418592</td>\n",
       "<td>299 / 7,143</td></tr>\n",
       "<tr><td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>61.0</td>\n",
       "<td>479.0</td>\n",
       "<td>0.0</td>\n",
       "<td>20.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.1476868</td>\n",
       "<td>83 / 562</td></tr>\n",
       "<tr><td>29.0</td>\n",
       "<td>432.0</td>\n",
       "<td>24.0</td>\n",
       "<td>0.0</td>\n",
       "<td>1377.0</td>\n",
       "<td>8.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.2636364</td>\n",
       "<td>493 / 1,870</td></tr>\n",
       "<tr><td>0.0</td>\n",
       "<td>129.0</td>\n",
       "<td>212.0</td>\n",
       "<td>19.0</td>\n",
       "<td>3.0</td>\n",
       "<td>3101.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.1047921</td>\n",
       "<td>363 / 3,464</td></tr>\n",
       "<tr><td>204.0</td>\n",
       "<td>16.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>3878.0</td>\n",
       "<td>0.0539156</td>\n",
       "<td>221 / 4,099</td></tr>\n",
       "<tr><td>41226.0</td>\n",
       "<td>58236.0</td>\n",
       "<td>7245.0</td>\n",
       "<td>528.0</td>\n",
       "<td>1482.0</td>\n",
       "<td>3326.0</td>\n",
       "<td>3975.0</td>\n",
       "<td>0.0552242</td>\n",
       "<td>6,407 / 116,018</td></tr></table></div>"
      ],
      "text/plain": [
       "class_1    class_2    class_3    class_4    class_5    class_6    class_7    Error      Rate\n",
       "---------  ---------  ---------  ---------  ---------  ---------  ---------  ---------  ---------------\n",
       "39403      2998       0          0          15         2          82         0.0728706  3,097 / 42,500\n",
       "1589       54529      104        0          83         60         15         0.0328308  1,851 / 56,380\n",
       "0          131        6844       30         3          135        0          0.0418592  299 / 7,143\n",
       "1          1          61         479        0          20         0          0.147687   83 / 562\n",
       "29         432        24         0          1377       8          0          0.263636   493 / 1,870\n",
       "0          129        212        19         3          3101       0          0.104792   363 / 3,464\n",
       "204        16         0          0          1          0          3878       0.0539156  221 / 4,099\n",
       "41226      58236      7245       528        1482       3326       3975       0.0552242  6,407 / 116,018"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-7 Hit Ratios: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>k</b></td>\n",
       "<td><b>hit_ratio</b></td></tr>\n",
       "<tr><td>1</td>\n",
       "<td>0.9447758</td></tr>\n",
       "<tr><td>2</td>\n",
       "<td>0.9978452</td></tr>\n",
       "<tr><td>3</td>\n",
       "<td>0.9996811</td></tr>\n",
       "<tr><td>4</td>\n",
       "<td>0.9997845</td></tr>\n",
       "<tr><td>5</td>\n",
       "<td>0.9997932</td></tr>\n",
       "<tr><td>6</td>\n",
       "<td>0.9997932</td></tr>\n",
       "<tr><td>7</td>\n",
       "<td>1.0</td></tr></table></div>"
      ],
      "text/plain": [
       "k    hit_ratio\n",
       "---  -----------\n",
       "1    0.944776\n",
       "2    0.997845\n",
       "3    0.999681\n",
       "4    0.999784\n",
       "5    0.999793\n",
       "6    0.999793\n",
       "7    1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scoring History: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>timestamp</b></td>\n",
       "<td><b>duration</b></td>\n",
       "<td><b>number_of_trees</b></td>\n",
       "<td><b>training_rmse</b></td>\n",
       "<td><b>training_logloss</b></td>\n",
       "<td><b>training_classification_error</b></td>\n",
       "<td><b>validation_rmse</b></td>\n",
       "<td><b>validation_logloss</b></td>\n",
       "<td><b>validation_classification_error</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>2019-02-09 15:08:03</td>\n",
       "<td> 0.033 sec</td>\n",
       "<td>0.0</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2019-02-09 15:08:05</td>\n",
       "<td> 2.084 sec</td>\n",
       "<td>1.0</td>\n",
       "<td>0.3356442</td>\n",
       "<td>2.4967403</td>\n",
       "<td>0.1239456</td>\n",
       "<td>0.3342398</td>\n",
       "<td>2.4447915</td>\n",
       "<td>0.1272906</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2019-02-09 15:08:07</td>\n",
       "<td> 3.945 sec</td>\n",
       "<td>2.0</td>\n",
       "<td>0.3192478</td>\n",
       "<td>2.1652719</td>\n",
       "<td>0.1135361</td>\n",
       "<td>0.2663761</td>\n",
       "<td>0.7915252</td>\n",
       "<td>0.0850127</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2019-02-09 15:08:08</td>\n",
       "<td> 5.272 sec</td>\n",
       "<td>3.0</td>\n",
       "<td>0.3061849</td>\n",
       "<td>1.8191096</td>\n",
       "<td>0.1055723</td>\n",
       "<td>0.2506499</td>\n",
       "<td>0.4602991</td>\n",
       "<td>0.0723336</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2019-02-09 15:08:10</td>\n",
       "<td> 6.947 sec</td>\n",
       "<td>4.0</td>\n",
       "<td>0.2953465</td>\n",
       "<td>1.5013414</td>\n",
       "<td>0.0992534</td>\n",
       "<td>0.2449232</td>\n",
       "<td>0.3418711</td>\n",
       "<td>0.0674033</td></tr>\n",
       "<tr><td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2019-02-09 15:08:53</td>\n",
       "<td>50.229 sec</td>\n",
       "<td>20.0</td>\n",
       "<td>0.2385726</td>\n",
       "<td>0.2613526</td>\n",
       "<td>0.0620141</td>\n",
       "<td>0.2307102</td>\n",
       "<td>0.2016582</td>\n",
       "<td>0.0560861</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2019-02-09 15:08:56</td>\n",
       "<td>53.486 sec</td>\n",
       "<td>21.0</td>\n",
       "<td>0.2380320</td>\n",
       "<td>0.2537838</td>\n",
       "<td>0.0615603</td>\n",
       "<td>0.2306266</td>\n",
       "<td>0.2008930</td>\n",
       "<td>0.0556638</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2019-02-09 15:09:00</td>\n",
       "<td>57.085 sec</td>\n",
       "<td>22.0</td>\n",
       "<td>0.2373729</td>\n",
       "<td>0.2481413</td>\n",
       "<td>0.0611638</td>\n",
       "<td>0.2303363</td>\n",
       "<td>0.2003093</td>\n",
       "<td>0.0554483</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2019-02-09 15:09:04</td>\n",
       "<td> 1 min  0.788 sec</td>\n",
       "<td>23.0</td>\n",
       "<td>0.2372012</td>\n",
       "<td>0.2436721</td>\n",
       "<td>0.0609024</td>\n",
       "<td>0.2305332</td>\n",
       "<td>0.2008905</td>\n",
       "<td>0.0553535</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2019-02-09 15:09:07</td>\n",
       "<td> 1 min  4.140 sec</td>\n",
       "<td>24.0</td>\n",
       "<td>0.2368055</td>\n",
       "<td>0.2384330</td>\n",
       "<td>0.0604198</td>\n",
       "<td>0.2305242</td>\n",
       "<td>0.2003041</td>\n",
       "<td>0.0552242</td></tr></table></div>"
      ],
      "text/plain": [
       "     timestamp            duration          number_of_trees    training_rmse        training_logloss     training_classification_error    validation_rmse      validation_logloss    validation_classification_error\n",
       "---  -------------------  ----------------  -----------------  -------------------  -------------------  -------------------------------  -------------------  --------------------  ---------------------------------\n",
       "     2019-02-09 15:08:03  0.033 sec         0.0                nan                  nan                  nan                              nan                  nan                   nan\n",
       "     2019-02-09 15:08:05  2.084 sec         1.0                0.3356442295518685   2.4967402651062605   0.12394557081324434              0.3342397945241896   2.4447915203481614    0.1272905928390422\n",
       "     2019-02-09 15:08:07  3.945 sec         2.0                0.3192478425096615   2.165271872295749    0.11353611731683565              0.2663761140912684   0.7915252219684008    0.08501267044768915\n",
       "     2019-02-09 15:08:08  5.272 sec         3.0                0.3061848841508862   1.8191095938718644   0.10557227472253637              0.25064994353297926  0.46029908231444594   0.07233360340636798\n",
       "     2019-02-09 15:08:10  6.947 sec         4.0                0.29534650012679087  1.5013413955219004   0.09925338578898094              0.2449232087930186   0.3418711327991444    0.06740333396541916\n",
       "---  ---                  ---               ---                ---                  ---                  ---                              ---                  ---                   ---\n",
       "     2019-02-09 15:08:53  50.229 sec        20.0               0.238572631380085    0.26135256527830864  0.062014126681662535             0.23071017224016566  0.2016581802224912    0.05608612456687755\n",
       "     2019-02-09 15:08:56  53.486 sec        21.0               0.23803201246820724  0.2537837863259223   0.0615603267706044               0.23062659797200138  0.20089303361874825   0.055663776310572496\n",
       "     2019-02-09 15:09:00  57.085 sec        22.0               0.23737294812878082  0.24814128403587804  0.06116384954598464              0.2303363353675695   0.20030933664714262   0.05544829250633523\n",
       "     2019-02-09 15:09:04  1 min  0.788 sec  23.0               0.23720115977740236  0.2436720823695402   0.06090240429110518              0.2305331776105485   0.20089046759678575   0.05535347963247082\n",
       "     2019-02-09 15:09:07  1 min  4.140 sec  24.0               0.23680548950456107  0.2384329935890688   0.06041981845688351              0.23052420467968346  0.20030408050020734   0.05522418934992846"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "See the whole table with table.as_data_frame()\n",
      "Variable Importances: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>variable</b></td>\n",
       "<td><b>relative_importance</b></td>\n",
       "<td><b>scaled_importance</b></td>\n",
       "<td><b>percentage</b></td></tr>\n",
       "<tr><td>Soil_Type</td>\n",
       "<td>784024.0625000</td>\n",
       "<td>1.0</td>\n",
       "<td>0.2524228</td></tr>\n",
       "<tr><td>Elevation</td>\n",
       "<td>738730.6250000</td>\n",
       "<td>0.9422295</td>\n",
       "<td>0.2378402</td></tr>\n",
       "<tr><td>Horizontal_Distance_To_Roadways</td>\n",
       "<td>327317.3125000</td>\n",
       "<td>0.4174838</td>\n",
       "<td>0.1053824</td></tr>\n",
       "<tr><td>Horizontal_Distance_To_Fire_Points</td>\n",
       "<td>317908.1875000</td>\n",
       "<td>0.4054827</td>\n",
       "<td>0.1023531</td></tr>\n",
       "<tr><td>Wilderness_Area</td>\n",
       "<td>178298.4375000</td>\n",
       "<td>0.2274145</td>\n",
       "<td>0.0574046</td></tr>\n",
       "<tr><td>Horizontal_Distance_To_Hydrology</td>\n",
       "<td>159165.6250000</td>\n",
       "<td>0.2030111</td>\n",
       "<td>0.0512446</td></tr>\n",
       "<tr><td>Vertical_Distance_To_Hydrology</td>\n",
       "<td>134396.0781250</td>\n",
       "<td>0.1714183</td>\n",
       "<td>0.0432699</td></tr>\n",
       "<tr><td>Aspect</td>\n",
       "<td>106049.9843750</td>\n",
       "<td>0.1352637</td>\n",
       "<td>0.0341436</td></tr>\n",
       "<tr><td>Hillshade_Noon</td>\n",
       "<td>99759.4375000</td>\n",
       "<td>0.1272403</td>\n",
       "<td>0.0321183</td></tr>\n",
       "<tr><td>Hillshade_9am</td>\n",
       "<td>92490.7421875</td>\n",
       "<td>0.1179693</td>\n",
       "<td>0.0297781</td></tr>\n",
       "<tr><td>Hillshade_3pm</td>\n",
       "<td>87322.4375000</td>\n",
       "<td>0.1113772</td>\n",
       "<td>0.0281142</td></tr>\n",
       "<tr><td>Slope</td>\n",
       "<td>80532.8671875</td>\n",
       "<td>0.1027173</td>\n",
       "<td>0.0259282</td></tr></table></div>"
      ],
      "text/plain": [
       "variable                            relative_importance    scaled_importance    percentage\n",
       "----------------------------------  ---------------------  -------------------  ------------\n",
       "Soil_Type                           784024                 1                    0.252423\n",
       "Elevation                           738731                 0.94223              0.23784\n",
       "Horizontal_Distance_To_Roadways     327317                 0.417484             0.105382\n",
       "Horizontal_Distance_To_Fire_Points  317908                 0.405483             0.102353\n",
       "Wilderness_Area                     178298                 0.227414             0.0574046\n",
       "Horizontal_Distance_To_Hydrology    159166                 0.203011             0.0512446\n",
       "Vertical_Distance_To_Hydrology      134396                 0.171418             0.0432699\n",
       "Aspect                              106050                 0.135264             0.0341436\n",
       "Hillshade_Noon                      99759.4                0.12724              0.0321183\n",
       "Hillshade_9am                       92490.7                0.117969             0.0297781\n",
       "Hillshade_3pm                       87322.4                0.111377             0.0281142\n",
       "Slope                               80532.9                0.102717             0.0259282"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_v1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To look at validation statistics, we can use the scoring history function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>duration</th>\n",
       "      <th>number_of_trees</th>\n",
       "      <th>training_rmse</th>\n",
       "      <th>training_logloss</th>\n",
       "      <th>training_classification_error</th>\n",
       "      <th>validation_rmse</th>\n",
       "      <th>validation_logloss</th>\n",
       "      <th>validation_classification_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>2019-02-09 15:08:03</td>\n",
       "      <td>0.033 sec</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td></td>\n",
       "      <td>2019-02-09 15:08:05</td>\n",
       "      <td>2.084 sec</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.335644</td>\n",
       "      <td>2.496740</td>\n",
       "      <td>0.123946</td>\n",
       "      <td>0.334240</td>\n",
       "      <td>2.444792</td>\n",
       "      <td>0.127291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "      <td>2019-02-09 15:08:07</td>\n",
       "      <td>3.945 sec</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.319248</td>\n",
       "      <td>2.165272</td>\n",
       "      <td>0.113536</td>\n",
       "      <td>0.266376</td>\n",
       "      <td>0.791525</td>\n",
       "      <td>0.085013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td></td>\n",
       "      <td>2019-02-09 15:08:08</td>\n",
       "      <td>5.272 sec</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.306185</td>\n",
       "      <td>1.819110</td>\n",
       "      <td>0.105572</td>\n",
       "      <td>0.250650</td>\n",
       "      <td>0.460299</td>\n",
       "      <td>0.072334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td></td>\n",
       "      <td>2019-02-09 15:08:10</td>\n",
       "      <td>6.947 sec</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.295347</td>\n",
       "      <td>1.501341</td>\n",
       "      <td>0.099253</td>\n",
       "      <td>0.244923</td>\n",
       "      <td>0.341871</td>\n",
       "      <td>0.067403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td></td>\n",
       "      <td>2019-02-09 15:08:11</td>\n",
       "      <td>8.449 sec</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.285458</td>\n",
       "      <td>1.259114</td>\n",
       "      <td>0.093016</td>\n",
       "      <td>0.240228</td>\n",
       "      <td>0.284286</td>\n",
       "      <td>0.063619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td></td>\n",
       "      <td>2019-02-09 15:08:13</td>\n",
       "      <td>9.949 sec</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.276749</td>\n",
       "      <td>1.059652</td>\n",
       "      <td>0.087339</td>\n",
       "      <td>0.237109</td>\n",
       "      <td>0.253836</td>\n",
       "      <td>0.061215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td></td>\n",
       "      <td>2019-02-09 15:08:15</td>\n",
       "      <td>11.637 sec</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.271068</td>\n",
       "      <td>0.889017</td>\n",
       "      <td>0.084058</td>\n",
       "      <td>0.237045</td>\n",
       "      <td>0.242014</td>\n",
       "      <td>0.060637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td></td>\n",
       "      <td>2019-02-09 15:08:18</td>\n",
       "      <td>14.708 sec</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.264125</td>\n",
       "      <td>0.748301</td>\n",
       "      <td>0.079793</td>\n",
       "      <td>0.234717</td>\n",
       "      <td>0.228079</td>\n",
       "      <td>0.059456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td></td>\n",
       "      <td>2019-02-09 15:08:19</td>\n",
       "      <td>16.463 sec</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.259892</td>\n",
       "      <td>0.640781</td>\n",
       "      <td>0.076880</td>\n",
       "      <td>0.234854</td>\n",
       "      <td>0.223989</td>\n",
       "      <td>0.058715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td></td>\n",
       "      <td>2019-02-09 15:08:21</td>\n",
       "      <td>18.396 sec</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.256376</td>\n",
       "      <td>0.558363</td>\n",
       "      <td>0.074640</td>\n",
       "      <td>0.234617</td>\n",
       "      <td>0.218316</td>\n",
       "      <td>0.058844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td></td>\n",
       "      <td>2019-02-09 15:08:23</td>\n",
       "      <td>20.515 sec</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.253835</td>\n",
       "      <td>0.490252</td>\n",
       "      <td>0.072745</td>\n",
       "      <td>0.234805</td>\n",
       "      <td>0.215974</td>\n",
       "      <td>0.058474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td></td>\n",
       "      <td>2019-02-09 15:08:27</td>\n",
       "      <td>24.086 sec</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.251131</td>\n",
       "      <td>0.432378</td>\n",
       "      <td>0.071127</td>\n",
       "      <td>0.234649</td>\n",
       "      <td>0.213046</td>\n",
       "      <td>0.058577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td></td>\n",
       "      <td>2019-02-09 15:08:30</td>\n",
       "      <td>27.196 sec</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.248991</td>\n",
       "      <td>0.389256</td>\n",
       "      <td>0.069729</td>\n",
       "      <td>0.234569</td>\n",
       "      <td>0.211600</td>\n",
       "      <td>0.058034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td></td>\n",
       "      <td>2019-02-09 15:08:33</td>\n",
       "      <td>30.569 sec</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.246333</td>\n",
       "      <td>0.358442</td>\n",
       "      <td>0.067829</td>\n",
       "      <td>0.233314</td>\n",
       "      <td>0.208885</td>\n",
       "      <td>0.057422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td></td>\n",
       "      <td>2019-02-09 15:08:37</td>\n",
       "      <td>34.388 sec</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.244445</td>\n",
       "      <td>0.331891</td>\n",
       "      <td>0.066566</td>\n",
       "      <td>0.232721</td>\n",
       "      <td>0.206468</td>\n",
       "      <td>0.057069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td></td>\n",
       "      <td>2019-02-09 15:08:40</td>\n",
       "      <td>36.858 sec</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.243268</td>\n",
       "      <td>0.310972</td>\n",
       "      <td>0.065848</td>\n",
       "      <td>0.232652</td>\n",
       "      <td>0.205486</td>\n",
       "      <td>0.056750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td></td>\n",
       "      <td>2019-02-09 15:08:42</td>\n",
       "      <td>39.474 sec</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.242160</td>\n",
       "      <td>0.295670</td>\n",
       "      <td>0.064915</td>\n",
       "      <td>0.232322</td>\n",
       "      <td>0.204266</td>\n",
       "      <td>0.056586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td></td>\n",
       "      <td>2019-02-09 15:08:45</td>\n",
       "      <td>42.334 sec</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.240674</td>\n",
       "      <td>0.281962</td>\n",
       "      <td>0.063733</td>\n",
       "      <td>0.231540</td>\n",
       "      <td>0.202981</td>\n",
       "      <td>0.056112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td></td>\n",
       "      <td>2019-02-09 15:08:48</td>\n",
       "      <td>45.174 sec</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.239493</td>\n",
       "      <td>0.270683</td>\n",
       "      <td>0.062786</td>\n",
       "      <td>0.231072</td>\n",
       "      <td>0.202246</td>\n",
       "      <td>0.056190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td></td>\n",
       "      <td>2019-02-09 15:08:53</td>\n",
       "      <td>50.229 sec</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.238573</td>\n",
       "      <td>0.261353</td>\n",
       "      <td>0.062014</td>\n",
       "      <td>0.230710</td>\n",
       "      <td>0.201658</td>\n",
       "      <td>0.056086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td></td>\n",
       "      <td>2019-02-09 15:08:56</td>\n",
       "      <td>53.486 sec</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.238032</td>\n",
       "      <td>0.253784</td>\n",
       "      <td>0.061560</td>\n",
       "      <td>0.230627</td>\n",
       "      <td>0.200893</td>\n",
       "      <td>0.055664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td></td>\n",
       "      <td>2019-02-09 15:09:00</td>\n",
       "      <td>57.085 sec</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.237373</td>\n",
       "      <td>0.248141</td>\n",
       "      <td>0.061164</td>\n",
       "      <td>0.230336</td>\n",
       "      <td>0.200309</td>\n",
       "      <td>0.055448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td></td>\n",
       "      <td>2019-02-09 15:09:04</td>\n",
       "      <td>1 min  0.788 sec</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.237201</td>\n",
       "      <td>0.243672</td>\n",
       "      <td>0.060902</td>\n",
       "      <td>0.230533</td>\n",
       "      <td>0.200890</td>\n",
       "      <td>0.055353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td></td>\n",
       "      <td>2019-02-09 15:09:07</td>\n",
       "      <td>1 min  4.140 sec</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.236805</td>\n",
       "      <td>0.238433</td>\n",
       "      <td>0.060420</td>\n",
       "      <td>0.230524</td>\n",
       "      <td>0.200304</td>\n",
       "      <td>0.055224</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                timestamp           duration  number_of_trees  training_rmse  \\\n",
       "0     2019-02-09 15:08:03          0.033 sec              0.0            NaN   \n",
       "1     2019-02-09 15:08:05          2.084 sec              1.0       0.335644   \n",
       "2     2019-02-09 15:08:07          3.945 sec              2.0       0.319248   \n",
       "3     2019-02-09 15:08:08          5.272 sec              3.0       0.306185   \n",
       "4     2019-02-09 15:08:10          6.947 sec              4.0       0.295347   \n",
       "5     2019-02-09 15:08:11          8.449 sec              5.0       0.285458   \n",
       "6     2019-02-09 15:08:13          9.949 sec              6.0       0.276749   \n",
       "7     2019-02-09 15:08:15         11.637 sec              7.0       0.271068   \n",
       "8     2019-02-09 15:08:18         14.708 sec              8.0       0.264125   \n",
       "9     2019-02-09 15:08:19         16.463 sec              9.0       0.259892   \n",
       "10    2019-02-09 15:08:21         18.396 sec             10.0       0.256376   \n",
       "11    2019-02-09 15:08:23         20.515 sec             11.0       0.253835   \n",
       "12    2019-02-09 15:08:27         24.086 sec             12.0       0.251131   \n",
       "13    2019-02-09 15:08:30         27.196 sec             13.0       0.248991   \n",
       "14    2019-02-09 15:08:33         30.569 sec             14.0       0.246333   \n",
       "15    2019-02-09 15:08:37         34.388 sec             15.0       0.244445   \n",
       "16    2019-02-09 15:08:40         36.858 sec             16.0       0.243268   \n",
       "17    2019-02-09 15:08:42         39.474 sec             17.0       0.242160   \n",
       "18    2019-02-09 15:08:45         42.334 sec             18.0       0.240674   \n",
       "19    2019-02-09 15:08:48         45.174 sec             19.0       0.239493   \n",
       "20    2019-02-09 15:08:53         50.229 sec             20.0       0.238573   \n",
       "21    2019-02-09 15:08:56         53.486 sec             21.0       0.238032   \n",
       "22    2019-02-09 15:09:00         57.085 sec             22.0       0.237373   \n",
       "23    2019-02-09 15:09:04   1 min  0.788 sec             23.0       0.237201   \n",
       "24    2019-02-09 15:09:07   1 min  4.140 sec             24.0       0.236805   \n",
       "\n",
       "    training_logloss  training_classification_error  validation_rmse  \\\n",
       "0                NaN                            NaN              NaN   \n",
       "1           2.496740                       0.123946         0.334240   \n",
       "2           2.165272                       0.113536         0.266376   \n",
       "3           1.819110                       0.105572         0.250650   \n",
       "4           1.501341                       0.099253         0.244923   \n",
       "5           1.259114                       0.093016         0.240228   \n",
       "6           1.059652                       0.087339         0.237109   \n",
       "7           0.889017                       0.084058         0.237045   \n",
       "8           0.748301                       0.079793         0.234717   \n",
       "9           0.640781                       0.076880         0.234854   \n",
       "10          0.558363                       0.074640         0.234617   \n",
       "11          0.490252                       0.072745         0.234805   \n",
       "12          0.432378                       0.071127         0.234649   \n",
       "13          0.389256                       0.069729         0.234569   \n",
       "14          0.358442                       0.067829         0.233314   \n",
       "15          0.331891                       0.066566         0.232721   \n",
       "16          0.310972                       0.065848         0.232652   \n",
       "17          0.295670                       0.064915         0.232322   \n",
       "18          0.281962                       0.063733         0.231540   \n",
       "19          0.270683                       0.062786         0.231072   \n",
       "20          0.261353                       0.062014         0.230710   \n",
       "21          0.253784                       0.061560         0.230627   \n",
       "22          0.248141                       0.061164         0.230336   \n",
       "23          0.243672                       0.060902         0.230533   \n",
       "24          0.238433                       0.060420         0.230524   \n",
       "\n",
       "    validation_logloss  validation_classification_error  \n",
       "0                  NaN                              NaN  \n",
       "1             2.444792                         0.127291  \n",
       "2             0.791525                         0.085013  \n",
       "3             0.460299                         0.072334  \n",
       "4             0.341871                         0.067403  \n",
       "5             0.284286                         0.063619  \n",
       "6             0.253836                         0.061215  \n",
       "7             0.242014                         0.060637  \n",
       "8             0.228079                         0.059456  \n",
       "9             0.223989                         0.058715  \n",
       "10            0.218316                         0.058844  \n",
       "11            0.215974                         0.058474  \n",
       "12            0.213046                         0.058577  \n",
       "13            0.211600                         0.058034  \n",
       "14            0.208885                         0.057422  \n",
       "15            0.206468                         0.057069  \n",
       "16            0.205486                         0.056750  \n",
       "17            0.204266                         0.056586  \n",
       "18            0.202981                         0.056112  \n",
       "19            0.202246                         0.056190  \n",
       "20            0.201658                         0.056086  \n",
       "21            0.200893                         0.055664  \n",
       "22            0.200309                         0.055448  \n",
       "23            0.200890                         0.055353  \n",
       "24            0.200304                         0.055224  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_v1.score_history()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can see the hit ratio table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-7 Hit Ratios: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>k</b></td>\n",
       "<td><b>hit_ratio</b></td></tr>\n",
       "<tr><td>1</td>\n",
       "<td>0.9447758</td></tr>\n",
       "<tr><td>2</td>\n",
       "<td>0.9978452</td></tr>\n",
       "<tr><td>3</td>\n",
       "<td>0.9996811</td></tr>\n",
       "<tr><td>4</td>\n",
       "<td>0.9997845</td></tr>\n",
       "<tr><td>5</td>\n",
       "<td>0.9997932</td></tr>\n",
       "<tr><td>6</td>\n",
       "<td>0.9997932</td></tr>\n",
       "<tr><td>7</td>\n",
       "<td>1.0</td></tr></table></div>"
      ],
      "text/plain": [
       "k    hit_ratio\n",
       "---  -----------\n",
       "1    0.944776\n",
       "2    0.997845\n",
       "3    0.999681\n",
       "4    0.999784\n",
       "5    0.999793\n",
       "6    0.999793\n",
       "7    1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_v1.hit_ratio_table(valid=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now for GBM\n",
    "\n",
    "First we will use all default settings, then make some changes to improve our predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gbm Model Build progress: || 100%\n"
     ]
    }
   ],
   "source": [
    "gbm_v1 = H2OGradientBoostingEstimator(\n",
    "    model_id=\"gbm_covType_v1\",\n",
    "    seed=2000000\n",
    ")\n",
    "gbm_v1.train(covtype_X, covtype_y, training_frame=train, validation_frame=valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>duration</th>\n",
       "      <th>number_of_trees</th>\n",
       "      <th>training_rmse</th>\n",
       "      <th>training_logloss</th>\n",
       "      <th>training_classification_error</th>\n",
       "      <th>validation_rmse</th>\n",
       "      <th>validation_logloss</th>\n",
       "      <th>validation_classification_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>2019-02-09 15:09:12</td>\n",
       "      <td>0.039 sec</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>1.945910</td>\n",
       "      <td>0.622472</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>1.945910</td>\n",
       "      <td>0.621429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td></td>\n",
       "      <td>2019-02-09 15:09:14</td>\n",
       "      <td>1.457 sec</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.802950</td>\n",
       "      <td>1.633685</td>\n",
       "      <td>0.259722</td>\n",
       "      <td>0.803065</td>\n",
       "      <td>1.634374</td>\n",
       "      <td>0.262330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "      <td>2019-02-09 15:09:14</td>\n",
       "      <td>2.130 sec</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.756429</td>\n",
       "      <td>1.432764</td>\n",
       "      <td>0.256757</td>\n",
       "      <td>0.756669</td>\n",
       "      <td>1.433968</td>\n",
       "      <td>0.258555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td></td>\n",
       "      <td>2019-02-09 15:09:15</td>\n",
       "      <td>2.769 sec</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.715237</td>\n",
       "      <td>1.284885</td>\n",
       "      <td>0.252385</td>\n",
       "      <td>0.715665</td>\n",
       "      <td>1.286751</td>\n",
       "      <td>0.254857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td></td>\n",
       "      <td>2019-02-09 15:09:15</td>\n",
       "      <td>3.398 sec</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.678832</td>\n",
       "      <td>1.170576</td>\n",
       "      <td>0.252316</td>\n",
       "      <td>0.679450</td>\n",
       "      <td>1.173003</td>\n",
       "      <td>0.253780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td></td>\n",
       "      <td>2019-02-09 15:09:16</td>\n",
       "      <td>4.022 sec</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.646422</td>\n",
       "      <td>1.078163</td>\n",
       "      <td>0.249665</td>\n",
       "      <td>0.647176</td>\n",
       "      <td>1.080859</td>\n",
       "      <td>0.251159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td></td>\n",
       "      <td>2019-02-09 15:09:20</td>\n",
       "      <td>8.169 sec</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.495028</td>\n",
       "      <td>0.713972</td>\n",
       "      <td>0.235509</td>\n",
       "      <td>0.496759</td>\n",
       "      <td>0.718390</td>\n",
       "      <td>0.237661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td></td>\n",
       "      <td>2019-02-09 15:09:25</td>\n",
       "      <td>13.333 sec</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.435449</td>\n",
       "      <td>0.581374</td>\n",
       "      <td>0.222369</td>\n",
       "      <td>0.437986</td>\n",
       "      <td>0.587285</td>\n",
       "      <td>0.225612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td></td>\n",
       "      <td>2019-02-09 15:09:31</td>\n",
       "      <td>19.307 sec</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.407285</td>\n",
       "      <td>0.518258</td>\n",
       "      <td>0.207879</td>\n",
       "      <td>0.410528</td>\n",
       "      <td>0.525352</td>\n",
       "      <td>0.211743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td></td>\n",
       "      <td>2019-02-09 15:09:37</td>\n",
       "      <td>25.355 sec</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.390641</td>\n",
       "      <td>0.481536</td>\n",
       "      <td>0.195628</td>\n",
       "      <td>0.394511</td>\n",
       "      <td>0.489773</td>\n",
       "      <td>0.199633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td></td>\n",
       "      <td>2019-02-09 15:09:44</td>\n",
       "      <td>32.426 sec</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0.379972</td>\n",
       "      <td>0.458326</td>\n",
       "      <td>0.186491</td>\n",
       "      <td>0.384399</td>\n",
       "      <td>0.467506</td>\n",
       "      <td>0.191255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td></td>\n",
       "      <td>2019-02-09 15:09:46</td>\n",
       "      <td>33.783 sec</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.378902</td>\n",
       "      <td>0.456017</td>\n",
       "      <td>0.185453</td>\n",
       "      <td>0.383381</td>\n",
       "      <td>0.465278</td>\n",
       "      <td>0.190281</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                timestamp    duration  number_of_trees  training_rmse  \\\n",
       "0     2019-02-09 15:09:12   0.039 sec              0.0       0.857143   \n",
       "1     2019-02-09 15:09:14   1.457 sec              1.0       0.802950   \n",
       "2     2019-02-09 15:09:14   2.130 sec              2.0       0.756429   \n",
       "3     2019-02-09 15:09:15   2.769 sec              3.0       0.715237   \n",
       "4     2019-02-09 15:09:15   3.398 sec              4.0       0.678832   \n",
       "5     2019-02-09 15:09:16   4.022 sec              5.0       0.646422   \n",
       "6     2019-02-09 15:09:20   8.169 sec             13.0       0.495028   \n",
       "7     2019-02-09 15:09:25  13.333 sec             22.0       0.435449   \n",
       "8     2019-02-09 15:09:31  19.307 sec             31.0       0.407285   \n",
       "9     2019-02-09 15:09:37  25.355 sec             40.0       0.390641   \n",
       "10    2019-02-09 15:09:44  32.426 sec             49.0       0.379972   \n",
       "11    2019-02-09 15:09:46  33.783 sec             50.0       0.378902   \n",
       "\n",
       "    training_logloss  training_classification_error  validation_rmse  \\\n",
       "0           1.945910                       0.622472         0.857143   \n",
       "1           1.633685                       0.259722         0.803065   \n",
       "2           1.432764                       0.256757         0.756669   \n",
       "3           1.284885                       0.252385         0.715665   \n",
       "4           1.170576                       0.252316         0.679450   \n",
       "5           1.078163                       0.249665         0.647176   \n",
       "6           0.713972                       0.235509         0.496759   \n",
       "7           0.581374                       0.222369         0.437986   \n",
       "8           0.518258                       0.207879         0.410528   \n",
       "9           0.481536                       0.195628         0.394511   \n",
       "10          0.458326                       0.186491         0.384399   \n",
       "11          0.456017                       0.185453         0.383381   \n",
       "\n",
       "    validation_logloss  validation_classification_error  \n",
       "0             1.945910                         0.621429  \n",
       "1             1.634374                         0.262330  \n",
       "2             1.433968                         0.258555  \n",
       "3             1.286751                         0.254857  \n",
       "4             1.173003                         0.253780  \n",
       "5             1.080859                         0.251159  \n",
       "6             0.718390                         0.237661  \n",
       "7             0.587285                         0.225612  \n",
       "8             0.525352                         0.211743  \n",
       "9             0.489773                         0.199633  \n",
       "10            0.467506                         0.191255  \n",
       "11            0.465278                         0.190281  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbm_v1.score_history()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-7 Hit Ratios: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>k</b></td>\n",
       "<td><b>hit_ratio</b></td></tr>\n",
       "<tr><td>1</td>\n",
       "<td>0.8097192</td></tr>\n",
       "<tr><td>2</td>\n",
       "<td>0.983244</td></tr>\n",
       "<tr><td>3</td>\n",
       "<td>0.9980606</td></tr>\n",
       "<tr><td>4</td>\n",
       "<td>0.9996983</td></tr>\n",
       "<tr><td>5</td>\n",
       "<td>0.9999828</td></tr>\n",
       "<tr><td>6</td>\n",
       "<td>0.9999914</td></tr>\n",
       "<tr><td>7</td>\n",
       "<td>1.0</td></tr></table></div>"
      ],
      "text/plain": [
       "k    hit_ratio\n",
       "---  -----------\n",
       "1    0.809719\n",
       "2    0.983244\n",
       "3    0.998061\n",
       "4    0.999698\n",
       "5    0.999983\n",
       "6    0.999991\n",
       "7    1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbm_v1.hit_ratio_table(valid=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This default GBM is much worse than our original random forest.  \n",
    "\n",
    "\n",
    "The GBM is far from converging, so there are three primary knobs to adjust to get our performance up if we want to keep a similar run time.  \n",
    "\n",
    "1: Adding trees will help. The default is 50.  \n",
    "2: Increasing the learning rate will also help. The contribution of each tree will be stronger, so the model will move further away from the overall mean.  \n",
    "3: Increasing the depth will help. This is the parameter that is the least straightforward. Tuning trees and learning rate both have direct impact that is easy to understand. Changing the depth means you are adjusting the \"weakness\" of each learner. Adding depth makes each tree fit the data closer.  \n",
    "  \n",
    "The first configuration will attack depth the most, since we've seen the random forest focus on a continuous variable (elevation) and 40-class factor (soil type) the most.  \n",
    "\n",
    "Also we will take a look at how to review a model while it is running.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GBM Round 2\n",
    "\n",
    "Let's do the following:\n",
    "\n",
    "1. decrease the number of trees to speed up runtime(from default 50 to 20)\n",
    "2. increase the learning rate (from default 0.1 to 0.2)\n",
    "3. increase the depth (from default 5 to 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gbm Model Build progress: || 100%\n"
     ]
    }
   ],
   "source": [
    "gbm_v2 = H2OGradientBoostingEstimator(\n",
    "    ntrees=20,\n",
    "    learn_rate=0.2,\n",
    "    max_depth=10,\n",
    "    stopping_tolerance=0.01, #10-fold increase in threshold as defined in rf_v1\n",
    "    stopping_rounds=2,\n",
    "    score_each_iteration=True,\n",
    "    model_id=\"gbm_covType_v2\",\n",
    "    seed=2000000\n",
    ")\n",
    "gbm_v2.train(covtype_X, covtype_y, training_frame=train, validation_frame=valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Live Performance Monitoring\n",
    "\n",
    "While this is running, we can actually look at the model. To do this we simply need a new connection to H2O. \n",
    "\n",
    "This Python notebook will run the model, so we need either another notebook or the web browser (or R, etc.). In this demo, we will use [Flow](http://localhost:54321) in our web browser http://localhost:54321 and the focus will be to look at model performance, since we are using Python to control H2O. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-7 Hit Ratios: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>k</b></td>\n",
       "<td><b>hit_ratio</b></td></tr>\n",
       "<tr><td>1</td>\n",
       "<td>0.9176852</td></tr>\n",
       "<tr><td>2</td>\n",
       "<td>0.9969315</td></tr>\n",
       "<tr><td>3</td>\n",
       "<td>0.9998535</td></tr>\n",
       "<tr><td>4</td>\n",
       "<td>0.9999828</td></tr>\n",
       "<tr><td>5</td>\n",
       "<td>1.0</td></tr>\n",
       "<tr><td>6</td>\n",
       "<td>1.0</td></tr>\n",
       "<tr><td>7</td>\n",
       "<td>1.0</td></tr></table></div>"
      ],
      "text/plain": [
       "k    hit_ratio\n",
       "---  -----------\n",
       "1    0.917685\n",
       "2    0.996932\n",
       "3    0.999853\n",
       "4    0.999983\n",
       "5    1\n",
       "6    1\n",
       "7    1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbm_v2.hit_ratio_table(valid=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This has moved us in the right direction, but still lower accuracy than the random forest.  \n",
    "\n",
    "It still has yet to converge, so we can make it more aggressive.  \n",
    "\n",
    "We can now add the stochastic nature of random forest into the GBM using some of the new H2O settings. This will help generalize and also provide a quicker runtime, so we can add a few more trees."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GBM: Third Time is the Charm\n",
    "\n",
    "1. Add a few trees(from 20 to 30)\n",
    "2. Increase learning rate (to 0.3)\n",
    "3. Use a random 70% of rows to fit each tree\n",
    "4. Use a random 70% of columns to fit each tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gbm Model Build progress: |"
     ]
    }
   ],
   "source": [
    "gbm_v3 = H2OGradientBoostingEstimator(\n",
    "    ntrees=30,\n",
    "    learn_rate=0.3,\n",
    "    max_depth=10,\n",
    "    sample_rate=0.7,\n",
    "    col_sample_rate=0.7,\n",
    "    stopping_rounds=2,\n",
    "    stopping_tolerance=0.01, #10-fold increase in threshold as defined in rf_v1\n",
    "    score_each_iteration=True,\n",
    "    model_id=\"gbm_covType_v3\",\n",
    "    seed=2000000\n",
    ")\n",
    "gbm_v3.train(covtype_X, covtype_y, training_frame=train, validation_frame=valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm_v3.hit_ratio_table(valid=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parity\n",
    "\n",
    "Now the GBM is close to the initial random forest.\n",
    "\n",
    "However, we used a default random forest. Random forest's primary strength is how well it runs with standard parameters, and while there are only a few parameters to tune, we can experiment with those to see if it will make a difference.  \n",
    "\n",
    "The main parameters to tune are the tree depth and the mtries, which is the number of predictors to use.  \n",
    "\n",
    "The default depth of trees is 20. It is common to increase this number, to the point that in some implementations, the depth is unlimited. We will increase ours from 20 to 30.  \n",
    "\n",
    "Note that the default mtries depends on whether classification or regression is being run. The default for classification is one-third of the columns. The default for regression is the square root of the number of columns.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest #2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_v2 = H2ORandomForestEstimator(\n",
    "    model_id=\"rf_covType_v2\",\n",
    "    ntrees=200,\n",
    "    max_depth=30,\n",
    "    stopping_rounds=2,\n",
    "    stopping_tolerance=0.01,\n",
    "    score_each_iteration=True,\n",
    "    seed=3000000)\n",
    "rf_v2.train(covtype_X, covtype_y, training_frame=train, validation_frame=valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_v2.hit_ratio_table(valid=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Predictions\n",
    "\n",
    "Now that we have our validation accuracy up beyond 95%, we can start considering our test data.  \n",
    "We have withheld an extra test set to ensure that after all the parameter tuning we have repeatedly applied with the validation data, we still have a completely pristine data set upon which to test the predictive capacity of our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Excludes the \"Cover_Type\" column from the features provided\n",
    "final_rf_predictions = rf_v2.predict(test[:-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Technically, our model won't look at the [\"Cover_Type\"] column within the test data, as it is trained on a set of features not including \"Cover_Type\". It is up to the user whether to include it in the test frame provided for predictions, as it has no effect whatsoever.\n",
    "\n",
    "Let's take a peek at the first few rows of predictions returned by our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_rf_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compare these predictions to the accuracy we got from our experimentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#validation set accuracy\n",
    "rf_v2.hit_ratio_table(valid=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test set accuracy\n",
    "(final_rf_predictions['predict']==test['Cover_Type']).as_data_frame(use_pandas=True).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our final error rates are very similar between validation and test sets. This suggests that we did not overfit the validation set during our experimentation. This concludes our demo of H2O GBM and H2O Random Forests.\n",
    "\n",
    "\n",
    "### Shut down the cluster\n",
    "Shut down the cluster now that we are done using it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "h2o.shutdown(prompt=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Possible Further Steps\n",
    "\n",
    "Model-agnostic gains can be found in improving handling of categorical features. We could experiment with the nbins and nbins_cats settings to control the H2O splitting.The general guidance is to lower the number to increase generalization (avoid overfitting), increase to better fit the distribution.  \n",
    " \n",
    "A good example of adjusting this value is for nbins_cats to be increased to match the number of values in a category. Though usually unnecessary, this can improve performance if a problem has a very important categorical predictor.  \n",
    "\n",
    "\n",
    "With regards to our Random Forest, we could further experiment with deeper trees or a higher percentage of columns used (mtries).  \n",
    "\n",
    "The GBM can be set to converge a slower for optimal accuracy. If we were to relax our runtime requirements a little bit, we could balance the learn rate and number of trees used.  \n",
    "\n",
    "In a production setting where fine-grain accuracy is beneficial, it is common to set the learn rate to a very small number, such as 0.01 or smaller, and add trees to match.  \n",
    "\n",
    "Use of early stopping is very powerful in allowing the setting of a low learning rate and the building as many trees as needed until the desired convergence is met.\n",
    "\n",
    "### More information can be found in the [H2O Gradient Boosted Models booklet](http://h2o.ai/resources/), in our [H2O SlideShare Presentations](http://www.slideshare.net/0xdata/presentations), our [H2O YouTube channel](https://www.youtube.com/user/0xdata/), as well as on our [H2O Github Repository](https://github.com/h2oai/h2o-3/), especially in our [H2O GBM R tests](https://github.com/h2oai/h2o-3/tree/master/h2o-r/tests/testdir_algos/gbm), and [H2O GBM Python tests](https://github.com/h2oai/h2o-3/tree/master/h2o-py/tests/testdir_algos/gbm)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
